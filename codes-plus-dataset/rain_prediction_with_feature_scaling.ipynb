{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28BQqzKq74KT"
      },
      "source": [
        "# Rain Prediction with Feature Scaling\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lknsC0_pcoX"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC4QGFZIvawK",
        "outputId": "57c76d4b-df48-49f0-b7e9-8a7163b9cc53"
      },
      "outputs": [],
      "source": [
        "# !pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YcixR9jvZf6",
        "outputId": "fe2d83d3-4eb5-4de0-f574-754c5b9f653c"
      },
      "outputs": [],
      "source": [
        "# !pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ESGOmKb_oGXz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4GHajjskSq"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "guAWa10S7wSa"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"../weatherAUS.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "DBJRWWQqtNjC",
        "outputId": "f86fad6e-c377-4320-8e6c-df8ad3b47500"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>Albury</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>44.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WNW</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>Albury</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WNW</td>\n",
              "      <td>44.0</td>\n",
              "      <td>NNW</td>\n",
              "      <td>WSW</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>Albury</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>WSW</td>\n",
              "      <td>46.0</td>\n",
              "      <td>W</td>\n",
              "      <td>WSW</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>Albury</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NE</td>\n",
              "      <td>24.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>E</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>Albury</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>W</td>\n",
              "      <td>41.0</td>\n",
              "      <td>ENE</td>\n",
              "      <td>NW</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145455</th>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>2.8</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>E</td>\n",
              "      <td>31.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>ENE</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1024.6</td>\n",
              "      <td>1020.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1</td>\n",
              "      <td>22.4</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145456</th>\n",
              "      <td>2017-06-22</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>3.6</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NNW</td>\n",
              "      <td>22.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1023.5</td>\n",
              "      <td>1019.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145457</th>\n",
              "      <td>2017-06-23</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>5.4</td>\n",
              "      <td>26.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>37.0</td>\n",
              "      <td>SE</td>\n",
              "      <td>WNW</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>1016.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.5</td>\n",
              "      <td>26.1</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145458</th>\n",
              "      <td>2017-06-24</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>7.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SE</td>\n",
              "      <td>28.0</td>\n",
              "      <td>SSE</td>\n",
              "      <td>N</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145459</th>\n",
              "      <td>2017-06-25</td>\n",
              "      <td>Uluru</td>\n",
              "      <td>14.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ESE</td>\n",
              "      <td>ESE</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1020.2</td>\n",
              "      <td>1017.9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.9</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145460 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
              "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
              "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
              "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
              "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
              "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
              "...            ...      ...      ...      ...       ...          ...   \n",
              "145455  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
              "145456  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
              "145457  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
              "145458  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
              "145459  2017-06-25    Uluru     14.9      NaN       0.0          NaN   \n",
              "\n",
              "        Sunshine WindGustDir  WindGustSpeed WindDir9am WindDir3pm  \\\n",
              "0            NaN           W           44.0          W        WNW   \n",
              "1            NaN         WNW           44.0        NNW        WSW   \n",
              "2            NaN         WSW           46.0          W        WSW   \n",
              "3            NaN          NE           24.0         SE          E   \n",
              "4            NaN           W           41.0        ENE         NW   \n",
              "...          ...         ...            ...        ...        ...   \n",
              "145455       NaN           E           31.0         SE        ENE   \n",
              "145456       NaN         NNW           22.0         SE          N   \n",
              "145457       NaN           N           37.0         SE        WNW   \n",
              "145458       NaN          SE           28.0        SSE          N   \n",
              "145459       NaN         NaN            NaN        ESE        ESE   \n",
              "\n",
              "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
              "0               20.0          24.0         71.0         22.0       1007.7   \n",
              "1                4.0          22.0         44.0         25.0       1010.6   \n",
              "2               19.0          26.0         38.0         30.0       1007.6   \n",
              "3               11.0           9.0         45.0         16.0       1017.6   \n",
              "4                7.0          20.0         82.0         33.0       1010.8   \n",
              "...              ...           ...          ...          ...          ...   \n",
              "145455          13.0          11.0         51.0         24.0       1024.6   \n",
              "145456          13.0           9.0         56.0         21.0       1023.5   \n",
              "145457           9.0           9.0         53.0         24.0       1021.0   \n",
              "145458          13.0           7.0         51.0         24.0       1019.4   \n",
              "145459          17.0          17.0         62.0         36.0       1020.2   \n",
              "\n",
              "        Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm RainToday  \\\n",
              "0            1007.1       8.0       NaN     16.9     21.8        No   \n",
              "1            1007.8       NaN       NaN     17.2     24.3        No   \n",
              "2            1008.7       NaN       2.0     21.0     23.2        No   \n",
              "3            1012.8       NaN       NaN     18.1     26.5        No   \n",
              "4            1006.0       7.0       8.0     17.8     29.7        No   \n",
              "...             ...       ...       ...      ...      ...       ...   \n",
              "145455       1020.3       NaN       NaN     10.1     22.4        No   \n",
              "145456       1019.1       NaN       NaN     10.9     24.5        No   \n",
              "145457       1016.8       NaN       NaN     12.5     26.1        No   \n",
              "145458       1016.5       3.0       2.0     15.1     26.0        No   \n",
              "145459       1017.9       8.0       8.0     15.0     20.9        No   \n",
              "\n",
              "       RainTomorrow  \n",
              "0                No  \n",
              "1                No  \n",
              "2                No  \n",
              "3                No  \n",
              "4                No  \n",
              "...             ...  \n",
              "145455           No  \n",
              "145456           No  \n",
              "145457           No  \n",
              "145458           No  \n",
              "145459          NaN  \n",
              "\n",
              "[145460 rows x 23 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option(\"display.max_columns\", None) # shows all the columns\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PdYqy_CxRyH"
      },
      "source": [
        "## Counting different features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CWvKWukYwykO"
      },
      "outputs": [],
      "source": [
        "numerical_features = [feature for feature in dataset.columns if dataset[feature].dtypes != 'object']\n",
        "continuous_features = [feature for feature in numerical_features if len(dataset[feature].unique()) >= 25]\n",
        "categorical_features = [feature for feature in dataset.columns if feature not in numerical_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi2IrbDSxVmd",
        "outputId": "4db40f03-4cd8-4a85-f01e-676415712c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical features =  16\n",
            "['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
            "Continuous features =  14\n",
            "['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Temp9am', 'Temp3pm']\n",
            "\n",
            "Categorical features =  7\n",
            "['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']\n"
          ]
        }
      ],
      "source": [
        "print(\"Numerical features = \", len(numerical_features))\n",
        "print(numerical_features)\n",
        "print(\"Continuous features = \", len(continuous_features))\n",
        "print(continuous_features)\n",
        "print(\"\\nCategorical features = \", len(categorical_features))\n",
        "print(categorical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8bfy79_bx4"
      },
      "source": [
        "## Encoding categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IqI_MoazB3EV"
      },
      "outputs": [],
      "source": [
        "windgustdir = {'NNW':0, 'NW':1, 'WNW':2, 'N':3, 'W':4, 'WSW':5, 'NNE':6, 'S':7, 'SSW':8, 'SW':9, 'SSE':10,\n",
        "               'NE':11, 'SE':12, 'ESE':13, 'ENE':14, 'E':15}\n",
        "winddir9am = {'NNW':0, 'N':1, 'NW':2, 'NNE':3, 'WNW':4, 'W':5, 'WSW':6, 'SW':7, 'SSW':8, 'NE':9, 'S':10,\n",
        "              'SSE':11, 'ENE':12, 'SE':13, 'ESE':14, 'E':15}\n",
        "winddir3pm = {'NW':0, 'NNW':1, 'N':2, 'WNW':3, 'W':4, 'NNE':5, 'WSW':6, 'SSW':7, 'S':8, 'SW':9, 'SE':10,\n",
        "               'NE':11, 'SSE':12, 'ENE':13, 'E':14, 'ESE':15}\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "\n",
        "dataset[\"WindGustDir\"] = encoder.fit_transform(dataset[[\"WindGustDir\"]].replace(windgustdir))\n",
        "dataset[\"WindDir9am\"] = encoder.fit_transform(dataset[[\"WindDir9am\"]].replace(winddir9am))\n",
        "dataset[\"WindDir3pm\"] = encoder.fit_transform(dataset[[\"WindDir3pm\"]].replace(winddir3pm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PLGc2sgGJTEL"
      },
      "outputs": [],
      "source": [
        "dataset[\"RainToday\"] = pd.get_dummies(dataset[\"RainToday\"], drop_first = True)\n",
        "dataset[\"RainTomorrow\"] = pd.get_dummies(dataset[\"RainTomorrow\"], drop_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nxCqFF6H9W-Z"
      },
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "dataset['Location']= encoder.fit_transform(dataset['Location'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "34wWFcVa9dRH",
        "outputId": "a02e43db-faf5-4d98-b6d6-8b3feaadd923"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>2</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>2</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>2</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145455</th>\n",
              "      <td>2017-06-21</td>\n",
              "      <td>41</td>\n",
              "      <td>2.8</td>\n",
              "      <td>23.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1024.6</td>\n",
              "      <td>1020.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.1</td>\n",
              "      <td>22.4</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145456</th>\n",
              "      <td>2017-06-22</td>\n",
              "      <td>41</td>\n",
              "      <td>3.6</td>\n",
              "      <td>25.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1023.5</td>\n",
              "      <td>1019.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.9</td>\n",
              "      <td>24.5</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145457</th>\n",
              "      <td>2017-06-23</td>\n",
              "      <td>41</td>\n",
              "      <td>5.4</td>\n",
              "      <td>26.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1021.0</td>\n",
              "      <td>1016.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.5</td>\n",
              "      <td>26.1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145458</th>\n",
              "      <td>2017-06-24</td>\n",
              "      <td>41</td>\n",
              "      <td>7.8</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145459</th>\n",
              "      <td>2017-06-25</td>\n",
              "      <td>41</td>\n",
              "      <td>14.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1020.2</td>\n",
              "      <td>1017.9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.9</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>145460 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Date  Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
              "0       2008-12-01         2     13.4     22.9       0.6          NaN   \n",
              "1       2008-12-02         2      7.4     25.1       0.0          NaN   \n",
              "2       2008-12-03         2     12.9     25.7       0.0          NaN   \n",
              "3       2008-12-04         2      9.2     28.0       0.0          NaN   \n",
              "4       2008-12-05         2     17.5     32.3       1.0          NaN   \n",
              "...            ...       ...      ...      ...       ...          ...   \n",
              "145455  2017-06-21        41      2.8     23.4       0.0          NaN   \n",
              "145456  2017-06-22        41      3.6     25.3       0.0          NaN   \n",
              "145457  2017-06-23        41      5.4     26.9       0.0          NaN   \n",
              "145458  2017-06-24        41      7.8     27.0       0.0          NaN   \n",
              "145459  2017-06-25        41     14.9      NaN       0.0          NaN   \n",
              "\n",
              "        Sunshine  WindGustDir  WindGustSpeed  WindDir9am  WindDir3pm  \\\n",
              "0            NaN          4.0           44.0         5.0         3.0   \n",
              "1            NaN          2.0           44.0         0.0         6.0   \n",
              "2            NaN          5.0           46.0         5.0         6.0   \n",
              "3            NaN         11.0           24.0        13.0        14.0   \n",
              "4            NaN          4.0           41.0        12.0         0.0   \n",
              "...          ...          ...            ...         ...         ...   \n",
              "145455       NaN         15.0           31.0        13.0        13.0   \n",
              "145456       NaN          0.0           22.0        13.0         2.0   \n",
              "145457       NaN          3.0           37.0        13.0         3.0   \n",
              "145458       NaN         12.0           28.0        11.0         2.0   \n",
              "145459       NaN          NaN            NaN        14.0        15.0   \n",
              "\n",
              "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
              "0               20.0          24.0         71.0         22.0       1007.7   \n",
              "1                4.0          22.0         44.0         25.0       1010.6   \n",
              "2               19.0          26.0         38.0         30.0       1007.6   \n",
              "3               11.0           9.0         45.0         16.0       1017.6   \n",
              "4                7.0          20.0         82.0         33.0       1010.8   \n",
              "...              ...           ...          ...          ...          ...   \n",
              "145455          13.0          11.0         51.0         24.0       1024.6   \n",
              "145456          13.0           9.0         56.0         21.0       1023.5   \n",
              "145457           9.0           9.0         53.0         24.0       1021.0   \n",
              "145458          13.0           7.0         51.0         24.0       1019.4   \n",
              "145459          17.0          17.0         62.0         36.0       1020.2   \n",
              "\n",
              "        Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
              "0            1007.1       8.0       NaN     16.9     21.8      False   \n",
              "1            1007.8       NaN       NaN     17.2     24.3      False   \n",
              "2            1008.7       NaN       2.0     21.0     23.2      False   \n",
              "3            1012.8       NaN       NaN     18.1     26.5      False   \n",
              "4            1006.0       7.0       8.0     17.8     29.7      False   \n",
              "...             ...       ...       ...      ...      ...        ...   \n",
              "145455       1020.3       NaN       NaN     10.1     22.4      False   \n",
              "145456       1019.1       NaN       NaN     10.9     24.5      False   \n",
              "145457       1016.8       NaN       NaN     12.5     26.1      False   \n",
              "145458       1016.5       3.0       2.0     15.1     26.0      False   \n",
              "145459       1017.9       8.0       8.0     15.0     20.9      False   \n",
              "\n",
              "        RainTomorrow  \n",
              "0              False  \n",
              "1              False  \n",
              "2              False  \n",
              "3              False  \n",
              "4              False  \n",
              "...              ...  \n",
              "145455         False  \n",
              "145456         False  \n",
              "145457         False  \n",
              "145458         False  \n",
              "145459         False  \n",
              "\n",
              "[145460 rows x 23 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXTnt_0XwKPN"
      },
      "source": [
        "## Handling missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltfVTIF5tOEi",
        "outputId": "70bc4c72-4c10-49e5-a967-42f78d9e9d7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date              0.000000\n",
              "Location          0.000000\n",
              "MinTemp           1.020899\n",
              "MaxTemp           0.866905\n",
              "Rainfall          2.241853\n",
              "Evaporation      43.166506\n",
              "Sunshine         48.009762\n",
              "WindGustDir       7.098859\n",
              "WindGustSpeed     7.055548\n",
              "WindDir9am        7.263853\n",
              "WindDir3pm        2.906641\n",
              "WindSpeed9am      1.214767\n",
              "WindSpeed3pm      2.105046\n",
              "Humidity9am       1.824557\n",
              "Humidity3pm       3.098446\n",
              "Pressure9am      10.356799\n",
              "Pressure3pm      10.331363\n",
              "Cloud9am         38.421559\n",
              "Cloud3pm         40.807095\n",
              "Temp9am           1.214767\n",
              "Temp3pm           2.481094\n",
              "RainToday         0.000000\n",
              "RainTomorrow      0.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.isnull().sum()*100/len(dataset) # getting missing values in percentages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2fJZgOVKFBk"
      },
      "source": [
        "handling missing values for columns cloud9am, cloud3pm, evaporation, sunshine because they have the most missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p3f980jEwQb5"
      },
      "outputs": [],
      "source": [
        "def random_sample_imputation(df, column):\n",
        "    df[column] = df[column]\n",
        "    rand_sample = df[column].dropna().sample(df[column].isnull().sum(), random_state=0)\n",
        "    rand_sample.index = df[df[column].isnull()].index\n",
        "    df.loc[df[column].isnull(), column] = rand_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-fhA5Z__0hxg"
      },
      "outputs": [],
      "source": [
        "for col in ['Evaporation', 'Sunshine', 'Cloud3pm', 'Cloud9am']:\n",
        "  random_sample_imputation(dataset, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9S1FNZ51bDp",
        "outputId": "ed785e00-10f2-4a5f-db37-e2d5c4bd82e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date                 0\n",
              "Location             0\n",
              "MinTemp           1485\n",
              "MaxTemp           1261\n",
              "Rainfall          3261\n",
              "Evaporation          0\n",
              "Sunshine             0\n",
              "WindGustDir      10326\n",
              "WindGustSpeed    10263\n",
              "WindDir9am       10566\n",
              "WindDir3pm        4228\n",
              "WindSpeed9am      1767\n",
              "WindSpeed3pm      3062\n",
              "Humidity9am       2654\n",
              "Humidity3pm       4507\n",
              "Pressure9am      15065\n",
              "Pressure3pm      15028\n",
              "Cloud9am             0\n",
              "Cloud3pm             0\n",
              "Temp9am           1767\n",
              "Temp3pm           3609\n",
              "RainToday            0\n",
              "RainTomorrow         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sNfEHgbTJPGE"
      },
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "dataset[\"WindGustDir\"] = imputer.fit_transform(dataset[[\"WindGustDir\"]])\n",
        "dataset[\"WindDir9am\"] = imputer.fit_transform(dataset[[\"WindDir9am\"]])\n",
        "dataset[\"WindDir3pm\"] = imputer.fit_transform(dataset[[\"WindDir3pm\"]])\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# df['RainToday'] = le.fit_transform(df['RainToday'])\n",
        "# df['RainTomorrow'] = le.fit_transform(df['RainTomorrow'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI33031L1mQT",
        "outputId": "d7edbcf7-9d89-4fb4-a35d-4c329bd445bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date                 0\n",
              "Location             0\n",
              "MinTemp           1485\n",
              "MaxTemp           1261\n",
              "Rainfall          3261\n",
              "Evaporation          0\n",
              "Sunshine             0\n",
              "WindGustDir          0\n",
              "WindGustSpeed    10263\n",
              "WindDir9am           0\n",
              "WindDir3pm           0\n",
              "WindSpeed9am      1767\n",
              "WindSpeed3pm      3062\n",
              "Humidity9am       2654\n",
              "Humidity3pm       4507\n",
              "Pressure9am      15065\n",
              "Pressure3pm      15028\n",
              "Cloud9am             0\n",
              "Cloud3pm             0\n",
              "Temp9am           1767\n",
              "Temp3pm           3609\n",
              "RainToday            0\n",
              "RainTomorrow         0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auxrGk8e9fhI"
      },
      "source": [
        "Handling missing values of continuous features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MEbqI3or57Wa"
      },
      "outputs": [],
      "source": [
        "for feature in continuous_features:\n",
        "    if (dataset[feature].isnull().sum() * 100/len(dataset)) > 0:\n",
        "        dataset[feature] = dataset[feature].fillna(dataset[feature].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj_YdxTP9muE",
        "outputId": "54c95f0e-08d3-453f-aed9-5f1c221f8b9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Date             0\n",
              "Location         0\n",
              "MinTemp          0\n",
              "MaxTemp          0\n",
              "Rainfall         0\n",
              "Evaporation      0\n",
              "Sunshine         0\n",
              "WindGustDir      0\n",
              "WindGustSpeed    0\n",
              "WindDir9am       0\n",
              "WindDir3pm       0\n",
              "WindSpeed9am     0\n",
              "WindSpeed3pm     0\n",
              "Humidity9am      0\n",
              "Humidity3pm      0\n",
              "Pressure9am      0\n",
              "Pressure3pm      0\n",
              "Cloud9am         0\n",
              "Cloud3pm         0\n",
              "Temp9am          0\n",
              "Temp3pm          0\n",
              "RainToday        0\n",
              "RainTomorrow     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfxnag2oLtqa"
      },
      "source": [
        "## Coverting date column into pandas date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MLfJEHyZLz0v"
      },
      "outputs": [],
      "source": [
        "# dataset[\"Date\"] = pd.to_datetime(dataset[\"Date\"], format = \"%Y-%m-%dT\", errors = \"coerce\")\n",
        "dataset['Date'] = pd.to_datetime(dataset['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "N1_-8t-wL5lR"
      },
      "outputs": [],
      "source": [
        "dataset[\"Date_month\"] = dataset[\"Date\"].dt.month\n",
        "dataset[\"Date_day\"] = dataset[\"Date\"].dt.day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "XUV7avltMfzK",
        "outputId": "a9a17eb6-4972-4981-c03e-6ab295ffd7a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Location</th>\n",
              "      <th>MinTemp</th>\n",
              "      <th>MaxTemp</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Sunshine</th>\n",
              "      <th>WindGustDir</th>\n",
              "      <th>WindGustSpeed</th>\n",
              "      <th>WindDir9am</th>\n",
              "      <th>WindDir3pm</th>\n",
              "      <th>WindSpeed9am</th>\n",
              "      <th>WindSpeed3pm</th>\n",
              "      <th>Humidity9am</th>\n",
              "      <th>Humidity3pm</th>\n",
              "      <th>Pressure9am</th>\n",
              "      <th>Pressure3pm</th>\n",
              "      <th>Cloud9am</th>\n",
              "      <th>Cloud3pm</th>\n",
              "      <th>Temp9am</th>\n",
              "      <th>Temp3pm</th>\n",
              "      <th>RainToday</th>\n",
              "      <th>RainTomorrow</th>\n",
              "      <th>Date_month</th>\n",
              "      <th>Date_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2008-12-01</td>\n",
              "      <td>2</td>\n",
              "      <td>13.4</td>\n",
              "      <td>22.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2.4</td>\n",
              "      <td>8.3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1007.7</td>\n",
              "      <td>1007.1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.9</td>\n",
              "      <td>21.8</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2008-12-02</td>\n",
              "      <td>2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>25.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1010.6</td>\n",
              "      <td>1007.8</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>24.3</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2008-12-03</td>\n",
              "      <td>2</td>\n",
              "      <td>12.9</td>\n",
              "      <td>25.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1007.6</td>\n",
              "      <td>1008.7</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-12-04</td>\n",
              "      <td>2</td>\n",
              "      <td>9.2</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.4</td>\n",
              "      <td>8.9</td>\n",
              "      <td>11.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>1012.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.1</td>\n",
              "      <td>26.5</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2008-12-05</td>\n",
              "      <td>2</td>\n",
              "      <td>17.5</td>\n",
              "      <td>32.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1010.8</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>29.7</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
              "0 2008-12-01         2     13.4     22.9       0.6          2.4       8.3   \n",
              "1 2008-12-02         2      7.4     25.1       0.0          3.6      10.0   \n",
              "2 2008-12-03         2     12.9     25.7       0.0          2.6       4.4   \n",
              "3 2008-12-04         2      9.2     28.0       0.0         18.4       8.9   \n",
              "4 2008-12-05         2     17.5     32.3       1.0          5.4       3.0   \n",
              "\n",
              "   WindGustDir  WindGustSpeed  WindDir9am  WindDir3pm  WindSpeed9am  \\\n",
              "0          4.0           44.0         5.0         3.0          20.0   \n",
              "1          2.0           44.0         0.0         6.0           4.0   \n",
              "2          5.0           46.0         5.0         6.0          19.0   \n",
              "3         11.0           24.0        13.0        14.0          11.0   \n",
              "4          4.0           41.0        12.0         0.0           7.0   \n",
              "\n",
              "   WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  \\\n",
              "0          24.0         71.0         22.0       1007.7       1007.1       8.0   \n",
              "1          22.0         44.0         25.0       1010.6       1007.8       7.0   \n",
              "2          26.0         38.0         30.0       1007.6       1008.7       8.0   \n",
              "3           9.0         45.0         16.0       1017.6       1012.8       0.0   \n",
              "4          20.0         82.0         33.0       1010.8       1006.0       7.0   \n",
              "\n",
              "   Cloud3pm  Temp9am  Temp3pm  RainToday  RainTomorrow  Date_month  Date_day  \n",
              "0       0.0     16.9     21.8      False         False          12         1  \n",
              "1       1.0     17.2     24.3      False         False          12         2  \n",
              "2       2.0     21.0     23.2      False         False          12         3  \n",
              "3       5.0     18.1     26.5      False         False          12         4  \n",
              "4       8.0     17.8     29.7      False         False          12         5  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQlfYtQGcUsO"
      },
      "source": [
        "## Splitting the dataset into X and y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "edQjBNChcadF"
      },
      "outputs": [],
      "source": [
        "X = dataset.drop([\"RainTomorrow\", \"Date\"], axis=1)\n",
        "y = dataset[\"RainTomorrow\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdbLKwT4AXn4"
      },
      "source": [
        "## Applying feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4_TsH2TMAa5v"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la7kFTalcfeM"
      },
      "source": [
        "## Splitting the dataset into training and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D_CFBP8Vcihk"
      },
      "outputs": [],
      "source": [
        "# stratify helps us to ensure that class proportions in 'y' are maintained in both training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, stratify = y, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhFETdz-7wTN",
        "outputId": "1454f2d7-3402-45c8-e67d-3421ff08f726"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training and test sets:\n",
            "X_train = (116368, 23)\n",
            "X_test = (29092, 23)\n",
            "y_train = (116368,)\n",
            "y_test = (29092,)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of training and test sets:\\nX_train = {X_train.shape}\\nX_test = {X_test.shape}\\ny_train = {y_train.shape}\\ny_test = {y_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JraNZQ_ImFFb"
      },
      "source": [
        "## Applying SMOTE to address class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q72dy7WMmJSW",
        "outputId": "b76d06ae-6c46-4c34-8984-dd187d549337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes before fit Counter({False: 90866, True: 25502})\n",
            "Number of classes after fit Counter({False: 90866, True: 90866})\n"
          ]
        }
      ],
      "source": [
        "sm = SMOTE(random_state = 0)\n",
        "X_train_, y_train_ = sm.fit_resample(X_train, y_train)\n",
        "print(\"Number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"Number of classes after fit {}\".format(Counter(y_train_)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxhFNZ_wmzyl"
      },
      "source": [
        "# Fitting different models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MadVFFp3puJi"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "gPFx2X59pwF1",
        "outputId": "ecfbba94-901e-4559-a354-943a2c2e5115"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(random_state=0)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_lr = LogisticRegression(random_state = 0)\n",
        "classifier_lr.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIxa-0kKp0V4",
        "outputId": "2f653014-30b2-4992-bfe7-cc05b2a60c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[17893  4824]\n",
            " [ 1512  4863]]\n",
            "\n",
            "Accuracy = 78.22%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.79      0.85     22717\n",
            "        True       0.50      0.76      0.61      6375\n",
            "\n",
            "    accuracy                           0.78     29092\n",
            "   macro avg       0.71      0.78      0.73     29092\n",
            "weighted avg       0.83      0.78      0.80     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred1 = classifier_lr.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred1))\n",
        "\n",
        "accuracy1 = accuracy_score(y_test, y_pred1)\n",
        "print(f'\\nAccuracy = {accuracy1 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRGa90dcqDFZ"
      },
      "source": [
        "## KNN Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "BMqpZWhvqEsX",
        "outputId": "549b765c-4239-4269-d385-a70ab429e562"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_knn_5 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier_knn_5.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo4L-2mxqEXh",
        "outputId": "e7b7d037-a6a7-4fe8-94b6-ff4aa5621b4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[16710  6007]\n",
            " [ 1622  4753]]\n",
            "\n",
            "Accuracy = 73.78%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      0.74      0.81     22717\n",
            "        True       0.44      0.75      0.55      6375\n",
            "\n",
            "    accuracy                           0.74     29092\n",
            "   macro avg       0.68      0.74      0.68     29092\n",
            "weighted avg       0.81      0.74      0.76     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred2 = classifier_knn_5.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred2))\n",
        "\n",
        "accuracy2 = accuracy_score(y_test, y_pred2)\n",
        "print(f'\\nAccuracy = {accuracy2 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7t2RxOY7wTS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "gDFs5BHs7wTS",
        "outputId": "80da1cf4-e9d6-4c73-9663-17c85967eabb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=4)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_knn_4 = KNeighborsClassifier(n_neighbors = 4, metric = 'minkowski', p = 2)\n",
        "classifier_knn_4.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwnL_pdN7wTT",
        "outputId": "0cf51d39-cbff-4ba9-82f2-7c5f1a069e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[18303  4414]\n",
            " [ 2205  4170]]\n",
            "\n",
            "Accuracy = 77.25%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.89      0.81      0.85     22717\n",
            "        True       0.49      0.65      0.56      6375\n",
            "\n",
            "    accuracy                           0.77     29092\n",
            "   macro avg       0.69      0.73      0.70     29092\n",
            "weighted avg       0.80      0.77      0.78     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred22 = classifier_knn_4.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred22))\n",
        "\n",
        "accuracy22 = accuracy_score(y_test, y_pred22)\n",
        "print(f'\\nAccuracy = {accuracy22 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred22))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR6k_89U7wTT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "qQzl0gTs7wTT",
        "outputId": "875ea83a-9967-4b5c-c518-4772b2aae21c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_knn_3 = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
        "classifier_knn_3.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3LWfoiM7wTU",
        "outputId": "7a51f8c1-40cf-44a1-c943-4fb6c082db06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[17272  5445]\n",
            " [ 1884  4491]]\n",
            "\n",
            "Accuracy = 74.81%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.76      0.82     22717\n",
            "        True       0.45      0.70      0.55      6375\n",
            "\n",
            "    accuracy                           0.75     29092\n",
            "   macro avg       0.68      0.73      0.69     29092\n",
            "weighted avg       0.80      0.75      0.76     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred222 = classifier_knn_3.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred222))\n",
        "\n",
        "accuracy222 = accuracy_score(y_test, y_pred222)\n",
        "print(f'\\nAccuracy = {accuracy222 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred222))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFkacQ9jtImy"
      },
      "source": [
        "## SVM (non-linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "aaafjINvtL1N"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(random_state=0)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_svc_rbf = SVC(kernel = 'rbf', random_state = 0)\n",
        "classifier_svc_rbf.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "snNJx-EItLLH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[18604  4113]\n",
            " [ 1528  4847]]\n",
            "\n",
            "Accuracy = 80.61%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.92      0.82      0.87     22717\n",
            "        True       0.54      0.76      0.63      6375\n",
            "\n",
            "    accuracy                           0.81     29092\n",
            "   macro avg       0.73      0.79      0.75     29092\n",
            "weighted avg       0.84      0.81      0.82     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred4 = classifier_svc_rbf.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred4))\n",
        "\n",
        "accuracy4 = accuracy_score(y_test, y_pred4)\n",
        "print(f'\\nAccuracy = {accuracy4 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6XbXAoMp5cC"
      },
      "source": [
        "## Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Y5hNjcu6p8OS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_gnb = GaussianNB()\n",
        "classifier_gnb.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "bfuRlgB9p781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[18266  4451]\n",
            " [ 2023  4352]]\n",
            "\n",
            "Accuracy = 77.75%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.80      0.85     22717\n",
            "        True       0.49      0.68      0.57      6375\n",
            "\n",
            "    accuracy                           0.78     29092\n",
            "   macro avg       0.70      0.74      0.71     29092\n",
            "weighted avg       0.81      0.78      0.79     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred5 = classifier_gnb.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred5))\n",
        "\n",
        "accuracy5 = accuracy_score(y_test, y_pred5)\n",
        "print(f'\\nAccuracy = {accuracy5 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEVcWJ0WoMi8"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dU1F558Y7wTY"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', random_state=0)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_rf = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
        "classifier_rf.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S9uriCez7wTY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[20654  2063]\n",
            " [ 2414  3961]]\n",
            "\n",
            "Accuracy = 84.61%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.90      0.91      0.90     22717\n",
            "        True       0.66      0.62      0.64      6375\n",
            "\n",
            "    accuracy                           0.85     29092\n",
            "   macro avg       0.78      0.77      0.77     29092\n",
            "weighted avg       0.84      0.85      0.84     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred6 = classifier_rf.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred6))\n",
        "\n",
        "accuracy6 = accuracy_score(y_test, y_pred6)\n",
        "print(f'\\nAccuracy = {accuracy6 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il78MHcHppq9"
      },
      "source": [
        "## XGBoost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "71s5IrpuppCo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xgboost = XGBClassifier()\n",
        "xgboost.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "YtTd8k7UqQKv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[21403  1314]\n",
            " [ 2860  3515]]\n",
            "\n",
            "Accuracy = 85.65%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.94      0.91     22717\n",
            "        True       0.73      0.55      0.63      6375\n",
            "\n",
            "    accuracy                           0.86     29092\n",
            "   macro avg       0.81      0.75      0.77     29092\n",
            "weighted avg       0.85      0.86      0.85     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred7 = xgboost.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred7))\n",
        "\n",
        "accuracy7 = accuracy_score(y_test, y_pred7)\n",
        "print(f'\\nAccuracy = {accuracy7 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JsXHya6m8ps"
      },
      "source": [
        "## Catboost Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fsetPNT-nFEp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate set to 0.050311\n",
            "0:\ttotal: 269ms\tremaining: 8m 58s\n",
            "1:\ttotal: 361ms\tremaining: 6m\n",
            "2:\ttotal: 471ms\tremaining: 5m 13s\n",
            "3:\ttotal: 751ms\tremaining: 6m 14s\n",
            "4:\ttotal: 1.01s\tremaining: 6m 45s\n",
            "5:\ttotal: 1.14s\tremaining: 6m 17s\n",
            "6:\ttotal: 1.2s\tremaining: 5m 42s\n",
            "7:\ttotal: 1.32s\tremaining: 5m 29s\n",
            "8:\ttotal: 1.39s\tremaining: 5m 6s\n",
            "9:\ttotal: 1.45s\tremaining: 4m 48s\n",
            "10:\ttotal: 1.51s\tremaining: 4m 33s\n",
            "11:\ttotal: 1.61s\tremaining: 4m 27s\n",
            "12:\ttotal: 1.68s\tremaining: 4m 17s\n",
            "13:\ttotal: 1.76s\tremaining: 4m 10s\n",
            "14:\ttotal: 1.84s\tremaining: 4m 3s\n",
            "15:\ttotal: 1.93s\tremaining: 3m 59s\n",
            "16:\ttotal: 2s\tremaining: 3m 53s\n",
            "17:\ttotal: 2.07s\tremaining: 3m 48s\n",
            "18:\ttotal: 2.14s\tremaining: 3m 43s\n",
            "19:\ttotal: 2.21s\tremaining: 3m 38s\n",
            "20:\ttotal: 2.29s\tremaining: 3m 35s\n",
            "21:\ttotal: 2.37s\tremaining: 3m 33s\n",
            "22:\ttotal: 2.43s\tremaining: 3m 29s\n",
            "23:\ttotal: 2.49s\tremaining: 3m 25s\n",
            "24:\ttotal: 2.57s\tremaining: 3m 23s\n",
            "25:\ttotal: 2.67s\tremaining: 3m 22s\n",
            "26:\ttotal: 2.76s\tremaining: 3m 21s\n",
            "27:\ttotal: 2.87s\tremaining: 3m 22s\n",
            "28:\ttotal: 2.94s\tremaining: 3m 20s\n",
            "29:\ttotal: 3s\tremaining: 3m 17s\n",
            "30:\ttotal: 3.07s\tremaining: 3m 14s\n",
            "31:\ttotal: 3.37s\tremaining: 3m 27s\n",
            "32:\ttotal: 3.47s\tremaining: 3m 26s\n",
            "33:\ttotal: 3.56s\tremaining: 3m 25s\n",
            "34:\ttotal: 3.65s\tremaining: 3m 24s\n",
            "35:\ttotal: 3.75s\tremaining: 3m 24s\n",
            "36:\ttotal: 3.93s\tremaining: 3m 28s\n",
            "37:\ttotal: 4.34s\tremaining: 3m 44s\n",
            "38:\ttotal: 5.23s\tremaining: 4m 22s\n",
            "39:\ttotal: 5.76s\tremaining: 4m 42s\n",
            "40:\ttotal: 6.06s\tremaining: 4m 49s\n",
            "41:\ttotal: 6.45s\tremaining: 5m\n",
            "42:\ttotal: 6.96s\tremaining: 5m 16s\n",
            "43:\ttotal: 7.35s\tremaining: 5m 26s\n",
            "44:\ttotal: 7.76s\tremaining: 5m 37s\n",
            "45:\ttotal: 8.51s\tremaining: 6m 1s\n",
            "46:\ttotal: 8.99s\tremaining: 6m 13s\n",
            "47:\ttotal: 9.2s\tremaining: 6m 14s\n",
            "48:\ttotal: 9.38s\tremaining: 6m 13s\n",
            "49:\ttotal: 9.59s\tremaining: 6m 14s\n",
            "50:\ttotal: 9.77s\tremaining: 6m 13s\n",
            "51:\ttotal: 9.93s\tremaining: 6m 12s\n",
            "52:\ttotal: 10.2s\tremaining: 6m 13s\n",
            "53:\ttotal: 10.3s\tremaining: 6m 12s\n",
            "54:\ttotal: 10.6s\tremaining: 6m 15s\n",
            "55:\ttotal: 10.8s\tremaining: 6m 14s\n",
            "56:\ttotal: 11s\tremaining: 6m 13s\n",
            "57:\ttotal: 11.2s\tremaining: 6m 13s\n",
            "58:\ttotal: 11.3s\tremaining: 6m 13s\n",
            "59:\ttotal: 11.5s\tremaining: 6m 12s\n",
            "60:\ttotal: 11.7s\tremaining: 6m 12s\n",
            "61:\ttotal: 11.9s\tremaining: 6m 12s\n",
            "62:\ttotal: 12.1s\tremaining: 6m 10s\n",
            "63:\ttotal: 12.2s\tremaining: 6m 8s\n",
            "64:\ttotal: 12.4s\tremaining: 6m 9s\n",
            "65:\ttotal: 12.6s\tremaining: 6m 8s\n",
            "66:\ttotal: 12.9s\tremaining: 6m 12s\n",
            "67:\ttotal: 13.1s\tremaining: 6m 11s\n",
            "68:\ttotal: 13.3s\tremaining: 6m 11s\n",
            "69:\ttotal: 13.4s\tremaining: 6m 9s\n",
            "70:\ttotal: 13.6s\tremaining: 6m 8s\n",
            "71:\ttotal: 13.7s\tremaining: 6m 6s\n",
            "72:\ttotal: 13.9s\tremaining: 6m 8s\n",
            "73:\ttotal: 14.1s\tremaining: 6m 6s\n",
            "74:\ttotal: 14.2s\tremaining: 6m 4s\n",
            "75:\ttotal: 14.3s\tremaining: 6m 1s\n",
            "76:\ttotal: 14.4s\tremaining: 5m 59s\n",
            "77:\ttotal: 14.5s\tremaining: 5m 57s\n",
            "78:\ttotal: 14.7s\tremaining: 5m 58s\n",
            "79:\ttotal: 15.3s\tremaining: 6m 6s\n",
            "80:\ttotal: 15.6s\tremaining: 6m 9s\n",
            "81:\ttotal: 15.9s\tremaining: 6m 10s\n",
            "82:\ttotal: 16s\tremaining: 6m 9s\n",
            "83:\ttotal: 16.1s\tremaining: 6m 8s\n",
            "84:\ttotal: 16.3s\tremaining: 6m 6s\n",
            "85:\ttotal: 16.4s\tremaining: 6m 5s\n",
            "86:\ttotal: 16.8s\tremaining: 6m 8s\n",
            "87:\ttotal: 17.1s\tremaining: 6m 11s\n",
            "88:\ttotal: 17.4s\tremaining: 6m 13s\n",
            "89:\ttotal: 17.6s\tremaining: 6m 12s\n",
            "90:\ttotal: 17.7s\tremaining: 6m 11s\n",
            "91:\ttotal: 17.8s\tremaining: 6m 9s\n",
            "92:\ttotal: 17.9s\tremaining: 6m 6s\n",
            "93:\ttotal: 18s\tremaining: 6m 4s\n",
            "94:\ttotal: 18s\tremaining: 6m 1s\n",
            "95:\ttotal: 18.1s\tremaining: 5m 59s\n",
            "96:\ttotal: 18.2s\tremaining: 5m 57s\n",
            "97:\ttotal: 18.4s\tremaining: 5m 56s\n",
            "98:\ttotal: 18.5s\tremaining: 5m 55s\n",
            "99:\ttotal: 18.6s\tremaining: 5m 53s\n",
            "100:\ttotal: 18.7s\tremaining: 5m 51s\n",
            "101:\ttotal: 18.8s\tremaining: 5m 49s\n",
            "102:\ttotal: 18.9s\tremaining: 5m 47s\n",
            "103:\ttotal: 18.9s\tremaining: 5m 45s\n",
            "104:\ttotal: 19s\tremaining: 5m 42s\n",
            "105:\ttotal: 19.1s\tremaining: 5m 40s\n",
            "106:\ttotal: 19.1s\tremaining: 5m 38s\n",
            "107:\ttotal: 19.2s\tremaining: 5m 35s\n",
            "108:\ttotal: 19.3s\tremaining: 5m 34s\n",
            "109:\ttotal: 19.4s\tremaining: 5m 33s\n",
            "110:\ttotal: 19.5s\tremaining: 5m 32s\n",
            "111:\ttotal: 19.9s\tremaining: 5m 36s\n",
            "112:\ttotal: 20.1s\tremaining: 5m 35s\n",
            "113:\ttotal: 20.2s\tremaining: 5m 33s\n",
            "114:\ttotal: 20.3s\tremaining: 5m 32s\n",
            "115:\ttotal: 20.4s\tremaining: 5m 31s\n",
            "116:\ttotal: 20.5s\tremaining: 5m 29s\n",
            "117:\ttotal: 20.5s\tremaining: 5m 27s\n",
            "118:\ttotal: 20.6s\tremaining: 5m 25s\n",
            "119:\ttotal: 20.6s\tremaining: 5m 23s\n",
            "120:\ttotal: 20.7s\tremaining: 5m 22s\n",
            "121:\ttotal: 20.8s\tremaining: 5m 20s\n",
            "122:\ttotal: 20.9s\tremaining: 5m 19s\n",
            "123:\ttotal: 21s\tremaining: 5m 17s\n",
            "124:\ttotal: 21.1s\tremaining: 5m 16s\n",
            "125:\ttotal: 21.1s\tremaining: 5m 14s\n",
            "126:\ttotal: 21.2s\tremaining: 5m 12s\n",
            "127:\ttotal: 21.3s\tremaining: 5m 11s\n",
            "128:\ttotal: 21.4s\tremaining: 5m 9s\n",
            "129:\ttotal: 21.4s\tremaining: 5m 8s\n",
            "130:\ttotal: 21.5s\tremaining: 5m 6s\n",
            "131:\ttotal: 21.6s\tremaining: 5m 5s\n",
            "132:\ttotal: 21.6s\tremaining: 5m 3s\n",
            "133:\ttotal: 21.7s\tremaining: 5m 2s\n",
            "134:\ttotal: 21.7s\tremaining: 5m\n",
            "135:\ttotal: 21.8s\tremaining: 4m 59s\n",
            "136:\ttotal: 21.9s\tremaining: 4m 58s\n",
            "137:\ttotal: 22.1s\tremaining: 4m 57s\n",
            "138:\ttotal: 22.2s\tremaining: 4m 57s\n",
            "139:\ttotal: 22.3s\tremaining: 4m 55s\n",
            "140:\ttotal: 22.3s\tremaining: 4m 54s\n",
            "141:\ttotal: 22.5s\tremaining: 4m 53s\n",
            "142:\ttotal: 22.6s\tremaining: 4m 52s\n",
            "143:\ttotal: 22.7s\tremaining: 4m 52s\n",
            "144:\ttotal: 22.8s\tremaining: 4m 51s\n",
            "145:\ttotal: 22.9s\tremaining: 4m 50s\n",
            "146:\ttotal: 23s\tremaining: 4m 49s\n",
            "147:\ttotal: 23.1s\tremaining: 4m 48s\n",
            "148:\ttotal: 23.1s\tremaining: 4m 47s\n",
            "149:\ttotal: 23.2s\tremaining: 4m 45s\n",
            "150:\ttotal: 23.2s\tremaining: 4m 44s\n",
            "151:\ttotal: 23.3s\tremaining: 4m 43s\n",
            "152:\ttotal: 23.4s\tremaining: 4m 42s\n",
            "153:\ttotal: 23.5s\tremaining: 4m 41s\n",
            "154:\ttotal: 23.6s\tremaining: 4m 40s\n",
            "155:\ttotal: 23.7s\tremaining: 4m 39s\n",
            "156:\ttotal: 23.8s\tremaining: 4m 39s\n",
            "157:\ttotal: 23.9s\tremaining: 4m 38s\n",
            "158:\ttotal: 24s\tremaining: 4m 38s\n",
            "159:\ttotal: 24.1s\tremaining: 4m 36s\n",
            "160:\ttotal: 24.1s\tremaining: 4m 35s\n",
            "161:\ttotal: 24.2s\tremaining: 4m 34s\n",
            "162:\ttotal: 24.3s\tremaining: 4m 33s\n",
            "163:\ttotal: 24.3s\tremaining: 4m 32s\n",
            "164:\ttotal: 24.4s\tremaining: 4m 31s\n",
            "165:\ttotal: 24.5s\tremaining: 4m 30s\n",
            "166:\ttotal: 24.6s\tremaining: 4m 30s\n",
            "167:\ttotal: 24.7s\tremaining: 4m 29s\n",
            "168:\ttotal: 24.8s\tremaining: 4m 28s\n",
            "169:\ttotal: 24.9s\tremaining: 4m 27s\n",
            "170:\ttotal: 25s\tremaining: 4m 26s\n",
            "171:\ttotal: 25s\tremaining: 4m 25s\n",
            "172:\ttotal: 25.1s\tremaining: 4m 24s\n",
            "173:\ttotal: 25.2s\tremaining: 4m 23s\n",
            "174:\ttotal: 25.2s\tremaining: 4m 22s\n",
            "175:\ttotal: 25.3s\tremaining: 4m 21s\n",
            "176:\ttotal: 25.3s\tremaining: 4m 20s\n",
            "177:\ttotal: 25.4s\tremaining: 4m 20s\n",
            "178:\ttotal: 25.5s\tremaining: 4m 19s\n",
            "179:\ttotal: 25.5s\tremaining: 4m 18s\n",
            "180:\ttotal: 25.6s\tremaining: 4m 17s\n",
            "181:\ttotal: 25.6s\tremaining: 4m 16s\n",
            "182:\ttotal: 25.7s\tremaining: 4m 15s\n",
            "183:\ttotal: 25.8s\tremaining: 4m 14s\n",
            "184:\ttotal: 25.9s\tremaining: 4m 13s\n",
            "185:\ttotal: 25.9s\tremaining: 4m 12s\n",
            "186:\ttotal: 26s\tremaining: 4m 11s\n",
            "187:\ttotal: 26s\tremaining: 4m 11s\n",
            "188:\ttotal: 26.1s\tremaining: 4m 10s\n",
            "189:\ttotal: 26.2s\tremaining: 4m 9s\n",
            "190:\ttotal: 26.2s\tremaining: 4m 8s\n",
            "191:\ttotal: 26.3s\tremaining: 4m 7s\n",
            "192:\ttotal: 26.4s\tremaining: 4m 6s\n",
            "193:\ttotal: 26.4s\tremaining: 4m 6s\n",
            "194:\ttotal: 26.5s\tremaining: 4m 5s\n",
            "195:\ttotal: 26.6s\tremaining: 4m 4s\n",
            "196:\ttotal: 26.7s\tremaining: 4m 4s\n",
            "197:\ttotal: 26.8s\tremaining: 4m 3s\n",
            "198:\ttotal: 26.8s\tremaining: 4m 2s\n",
            "199:\ttotal: 26.9s\tremaining: 4m 2s\n",
            "200:\ttotal: 27s\tremaining: 4m 1s\n",
            "201:\ttotal: 27.1s\tremaining: 4m\n",
            "202:\ttotal: 27.1s\tremaining: 4m\n",
            "203:\ttotal: 27.2s\tremaining: 3m 59s\n",
            "204:\ttotal: 27.3s\tremaining: 3m 58s\n",
            "205:\ttotal: 27.4s\tremaining: 3m 58s\n",
            "206:\ttotal: 27.4s\tremaining: 3m 57s\n",
            "207:\ttotal: 27.5s\tremaining: 3m 57s\n",
            "208:\ttotal: 27.6s\tremaining: 3m 56s\n",
            "209:\ttotal: 27.7s\tremaining: 3m 55s\n",
            "210:\ttotal: 27.7s\tremaining: 3m 55s\n",
            "211:\ttotal: 27.8s\tremaining: 3m 54s\n",
            "212:\ttotal: 27.9s\tremaining: 3m 53s\n",
            "213:\ttotal: 28s\tremaining: 3m 53s\n",
            "214:\ttotal: 28.1s\tremaining: 3m 53s\n",
            "215:\ttotal: 28.2s\tremaining: 3m 52s\n",
            "216:\ttotal: 28.4s\tremaining: 3m 53s\n",
            "217:\ttotal: 28.5s\tremaining: 3m 52s\n",
            "218:\ttotal: 28.6s\tremaining: 3m 52s\n",
            "219:\ttotal: 28.7s\tremaining: 3m 51s\n",
            "220:\ttotal: 28.8s\tremaining: 3m 51s\n",
            "221:\ttotal: 28.8s\tremaining: 3m 50s\n",
            "222:\ttotal: 28.9s\tremaining: 3m 50s\n",
            "223:\ttotal: 29.1s\tremaining: 3m 50s\n",
            "224:\ttotal: 29.2s\tremaining: 3m 50s\n",
            "225:\ttotal: 29.3s\tremaining: 3m 50s\n",
            "226:\ttotal: 29.4s\tremaining: 3m 49s\n",
            "227:\ttotal: 29.6s\tremaining: 3m 50s\n",
            "228:\ttotal: 29.8s\tremaining: 3m 50s\n",
            "229:\ttotal: 29.9s\tremaining: 3m 50s\n",
            "230:\ttotal: 30s\tremaining: 3m 49s\n",
            "231:\ttotal: 30.1s\tremaining: 3m 49s\n",
            "232:\ttotal: 30.2s\tremaining: 3m 48s\n",
            "233:\ttotal: 30.3s\tremaining: 3m 48s\n",
            "234:\ttotal: 30.4s\tremaining: 3m 48s\n",
            "235:\ttotal: 30.5s\tremaining: 3m 48s\n",
            "236:\ttotal: 30.6s\tremaining: 3m 47s\n",
            "237:\ttotal: 30.8s\tremaining: 3m 48s\n",
            "238:\ttotal: 30.9s\tremaining: 3m 47s\n",
            "239:\ttotal: 31s\tremaining: 3m 47s\n",
            "240:\ttotal: 31.1s\tremaining: 3m 46s\n",
            "241:\ttotal: 31.2s\tremaining: 3m 46s\n",
            "242:\ttotal: 31.2s\tremaining: 3m 45s\n",
            "243:\ttotal: 31.3s\tremaining: 3m 45s\n",
            "244:\ttotal: 31.4s\tremaining: 3m 44s\n",
            "245:\ttotal: 31.4s\tremaining: 3m 44s\n",
            "246:\ttotal: 31.6s\tremaining: 3m 44s\n",
            "247:\ttotal: 31.7s\tremaining: 3m 44s\n",
            "248:\ttotal: 31.9s\tremaining: 3m 44s\n",
            "249:\ttotal: 32.4s\tremaining: 3m 46s\n",
            "250:\ttotal: 32.6s\tremaining: 3m 46s\n",
            "251:\ttotal: 32.7s\tremaining: 3m 46s\n",
            "252:\ttotal: 32.8s\tremaining: 3m 46s\n",
            "253:\ttotal: 33s\tremaining: 3m 46s\n",
            "254:\ttotal: 33s\tremaining: 3m 45s\n",
            "255:\ttotal: 33.1s\tremaining: 3m 45s\n",
            "256:\ttotal: 33.3s\tremaining: 3m 45s\n",
            "257:\ttotal: 33.4s\tremaining: 3m 45s\n",
            "258:\ttotal: 33.5s\tremaining: 3m 45s\n",
            "259:\ttotal: 33.7s\tremaining: 3m 45s\n",
            "260:\ttotal: 33.8s\tremaining: 3m 45s\n",
            "261:\ttotal: 33.9s\tremaining: 3m 45s\n",
            "262:\ttotal: 34s\tremaining: 3m 44s\n",
            "263:\ttotal: 34.2s\tremaining: 3m 44s\n",
            "264:\ttotal: 34.2s\tremaining: 3m 44s\n",
            "265:\ttotal: 34.3s\tremaining: 3m 43s\n",
            "266:\ttotal: 34.5s\tremaining: 3m 43s\n",
            "267:\ttotal: 34.6s\tremaining: 3m 43s\n",
            "268:\ttotal: 34.7s\tremaining: 3m 43s\n",
            "269:\ttotal: 34.8s\tremaining: 3m 43s\n",
            "270:\ttotal: 35s\tremaining: 3m 43s\n",
            "271:\ttotal: 35.2s\tremaining: 3m 43s\n",
            "272:\ttotal: 35.4s\tremaining: 3m 43s\n",
            "273:\ttotal: 35.4s\tremaining: 3m 43s\n",
            "274:\ttotal: 35.6s\tremaining: 3m 43s\n",
            "275:\ttotal: 35.7s\tremaining: 3m 43s\n",
            "276:\ttotal: 35.8s\tremaining: 3m 42s\n",
            "277:\ttotal: 35.9s\tremaining: 3m 42s\n",
            "278:\ttotal: 35.9s\tremaining: 3m 41s\n",
            "279:\ttotal: 36.1s\tremaining: 3m 41s\n",
            "280:\ttotal: 36.2s\tremaining: 3m 41s\n",
            "281:\ttotal: 36.3s\tremaining: 3m 41s\n",
            "282:\ttotal: 36.5s\tremaining: 3m 41s\n",
            "283:\ttotal: 36.6s\tremaining: 3m 41s\n",
            "284:\ttotal: 36.7s\tremaining: 3m 41s\n",
            "285:\ttotal: 37.1s\tremaining: 3m 42s\n",
            "286:\ttotal: 37.4s\tremaining: 3m 43s\n",
            "287:\ttotal: 37.6s\tremaining: 3m 43s\n",
            "288:\ttotal: 37.6s\tremaining: 3m 42s\n",
            "289:\ttotal: 37.7s\tremaining: 3m 42s\n",
            "290:\ttotal: 37.8s\tremaining: 3m 41s\n",
            "291:\ttotal: 37.9s\tremaining: 3m 41s\n",
            "292:\ttotal: 38.1s\tremaining: 3m 41s\n",
            "293:\ttotal: 38.2s\tremaining: 3m 41s\n",
            "294:\ttotal: 38.3s\tremaining: 3m 41s\n",
            "295:\ttotal: 38.4s\tremaining: 3m 41s\n",
            "296:\ttotal: 38.5s\tremaining: 3m 40s\n",
            "297:\ttotal: 38.5s\tremaining: 3m 40s\n",
            "298:\ttotal: 38.6s\tremaining: 3m 39s\n",
            "299:\ttotal: 38.8s\tremaining: 3m 39s\n",
            "300:\ttotal: 38.9s\tremaining: 3m 39s\n",
            "301:\ttotal: 38.9s\tremaining: 3m 38s\n",
            "302:\ttotal: 39s\tremaining: 3m 38s\n",
            "303:\ttotal: 39.2s\tremaining: 3m 38s\n",
            "304:\ttotal: 39.3s\tremaining: 3m 38s\n",
            "305:\ttotal: 39.3s\tremaining: 3m 37s\n",
            "306:\ttotal: 39.4s\tremaining: 3m 37s\n",
            "307:\ttotal: 39.5s\tremaining: 3m 36s\n",
            "308:\ttotal: 39.5s\tremaining: 3m 36s\n",
            "309:\ttotal: 39.6s\tremaining: 3m 35s\n",
            "310:\ttotal: 39.6s\tremaining: 3m 35s\n",
            "311:\ttotal: 39.7s\tremaining: 3m 34s\n",
            "312:\ttotal: 39.8s\tremaining: 3m 34s\n",
            "313:\ttotal: 39.9s\tremaining: 3m 33s\n",
            "314:\ttotal: 39.9s\tremaining: 3m 33s\n",
            "315:\ttotal: 40s\tremaining: 3m 33s\n",
            "316:\ttotal: 40.1s\tremaining: 3m 32s\n",
            "317:\ttotal: 40.2s\tremaining: 3m 32s\n",
            "318:\ttotal: 40.2s\tremaining: 3m 31s\n",
            "319:\ttotal: 40.3s\tremaining: 3m 31s\n",
            "320:\ttotal: 40.4s\tremaining: 3m 31s\n",
            "321:\ttotal: 40.4s\tremaining: 3m 30s\n",
            "322:\ttotal: 40.5s\tremaining: 3m 30s\n",
            "323:\ttotal: 40.6s\tremaining: 3m 29s\n",
            "324:\ttotal: 40.6s\tremaining: 3m 29s\n",
            "325:\ttotal: 40.7s\tremaining: 3m 28s\n",
            "326:\ttotal: 40.8s\tremaining: 3m 28s\n",
            "327:\ttotal: 40.8s\tremaining: 3m 28s\n",
            "328:\ttotal: 40.9s\tremaining: 3m 27s\n",
            "329:\ttotal: 41s\tremaining: 3m 27s\n",
            "330:\ttotal: 41.2s\tremaining: 3m 27s\n",
            "331:\ttotal: 41.3s\tremaining: 3m 27s\n",
            "332:\ttotal: 41.4s\tremaining: 3m 27s\n",
            "333:\ttotal: 41.5s\tremaining: 3m 26s\n",
            "334:\ttotal: 41.5s\tremaining: 3m 26s\n",
            "335:\ttotal: 41.6s\tremaining: 3m 26s\n",
            "336:\ttotal: 41.7s\tremaining: 3m 25s\n",
            "337:\ttotal: 41.9s\tremaining: 3m 25s\n",
            "338:\ttotal: 42s\tremaining: 3m 25s\n",
            "339:\ttotal: 42.1s\tremaining: 3m 25s\n",
            "340:\ttotal: 42.2s\tremaining: 3m 25s\n",
            "341:\ttotal: 42.3s\tremaining: 3m 24s\n",
            "342:\ttotal: 42.4s\tremaining: 3m 24s\n",
            "343:\ttotal: 42.4s\tremaining: 3m 24s\n",
            "344:\ttotal: 42.5s\tremaining: 3m 24s\n",
            "345:\ttotal: 42.7s\tremaining: 3m 23s\n",
            "346:\ttotal: 42.8s\tremaining: 3m 23s\n",
            "347:\ttotal: 42.8s\tremaining: 3m 23s\n",
            "348:\ttotal: 42.9s\tremaining: 3m 22s\n",
            "349:\ttotal: 43s\tremaining: 3m 22s\n",
            "350:\ttotal: 43.1s\tremaining: 3m 22s\n",
            "351:\ttotal: 43.1s\tremaining: 3m 21s\n",
            "352:\ttotal: 43.2s\tremaining: 3m 21s\n",
            "353:\ttotal: 43.3s\tremaining: 3m 21s\n",
            "354:\ttotal: 43.4s\tremaining: 3m 21s\n",
            "355:\ttotal: 43.5s\tremaining: 3m 20s\n",
            "356:\ttotal: 43.6s\tremaining: 3m 20s\n",
            "357:\ttotal: 43.8s\tremaining: 3m 20s\n",
            "358:\ttotal: 43.9s\tremaining: 3m 20s\n",
            "359:\ttotal: 44s\tremaining: 3m 20s\n",
            "360:\ttotal: 44.1s\tremaining: 3m 20s\n",
            "361:\ttotal: 44.2s\tremaining: 3m 19s\n",
            "362:\ttotal: 44.2s\tremaining: 3m 19s\n",
            "363:\ttotal: 44.3s\tremaining: 3m 19s\n",
            "364:\ttotal: 44.3s\tremaining: 3m 18s\n",
            "365:\ttotal: 44.4s\tremaining: 3m 18s\n",
            "366:\ttotal: 44.5s\tremaining: 3m 17s\n",
            "367:\ttotal: 44.5s\tremaining: 3m 17s\n",
            "368:\ttotal: 44.6s\tremaining: 3m 17s\n",
            "369:\ttotal: 44.6s\tremaining: 3m 16s\n",
            "370:\ttotal: 44.7s\tremaining: 3m 16s\n",
            "371:\ttotal: 44.8s\tremaining: 3m 16s\n",
            "372:\ttotal: 44.9s\tremaining: 3m 15s\n",
            "373:\ttotal: 44.9s\tremaining: 3m 15s\n",
            "374:\ttotal: 45s\tremaining: 3m 15s\n",
            "375:\ttotal: 45.1s\tremaining: 3m 14s\n",
            "376:\ttotal: 45.2s\tremaining: 3m 14s\n",
            "377:\ttotal: 45.3s\tremaining: 3m 14s\n",
            "378:\ttotal: 45.5s\tremaining: 3m 14s\n",
            "379:\ttotal: 45.6s\tremaining: 3m 14s\n",
            "380:\ttotal: 45.8s\tremaining: 3m 14s\n",
            "381:\ttotal: 45.9s\tremaining: 3m 14s\n",
            "382:\ttotal: 46s\tremaining: 3m 14s\n",
            "383:\ttotal: 46.1s\tremaining: 3m 14s\n",
            "384:\ttotal: 46.2s\tremaining: 3m 13s\n",
            "385:\ttotal: 46.3s\tremaining: 3m 13s\n",
            "386:\ttotal: 46.3s\tremaining: 3m 13s\n",
            "387:\ttotal: 46.4s\tremaining: 3m 12s\n",
            "388:\ttotal: 46.4s\tremaining: 3m 12s\n",
            "389:\ttotal: 46.5s\tremaining: 3m 11s\n",
            "390:\ttotal: 46.6s\tremaining: 3m 11s\n",
            "391:\ttotal: 46.6s\tremaining: 3m 11s\n",
            "392:\ttotal: 46.9s\tremaining: 3m 11s\n",
            "393:\ttotal: 47.2s\tremaining: 3m 12s\n",
            "394:\ttotal: 47.2s\tremaining: 3m 11s\n",
            "395:\ttotal: 47.3s\tremaining: 3m 11s\n",
            "396:\ttotal: 47.4s\tremaining: 3m 11s\n",
            "397:\ttotal: 47.5s\tremaining: 3m 11s\n",
            "398:\ttotal: 47.6s\tremaining: 3m 10s\n",
            "399:\ttotal: 47.6s\tremaining: 3m 10s\n",
            "400:\ttotal: 47.7s\tremaining: 3m 10s\n",
            "401:\ttotal: 47.8s\tremaining: 3m 9s\n",
            "402:\ttotal: 47.9s\tremaining: 3m 9s\n",
            "403:\ttotal: 48.1s\tremaining: 3m 9s\n",
            "404:\ttotal: 48.2s\tremaining: 3m 9s\n",
            "405:\ttotal: 48.3s\tremaining: 3m 9s\n",
            "406:\ttotal: 48.4s\tremaining: 3m 9s\n",
            "407:\ttotal: 48.5s\tremaining: 3m 9s\n",
            "408:\ttotal: 48.6s\tremaining: 3m 8s\n",
            "409:\ttotal: 48.6s\tremaining: 3m 8s\n",
            "410:\ttotal: 48.7s\tremaining: 3m 8s\n",
            "411:\ttotal: 48.8s\tremaining: 3m 8s\n",
            "412:\ttotal: 48.9s\tremaining: 3m 7s\n",
            "413:\ttotal: 49s\tremaining: 3m 7s\n",
            "414:\ttotal: 49.3s\tremaining: 3m 8s\n",
            "415:\ttotal: 49.4s\tremaining: 3m 8s\n",
            "416:\ttotal: 49.5s\tremaining: 3m 7s\n",
            "417:\ttotal: 49.6s\tremaining: 3m 7s\n",
            "418:\ttotal: 49.7s\tremaining: 3m 7s\n",
            "419:\ttotal: 49.7s\tremaining: 3m 7s\n",
            "420:\ttotal: 49.8s\tremaining: 3m 6s\n",
            "421:\ttotal: 49.9s\tremaining: 3m 6s\n",
            "422:\ttotal: 50s\tremaining: 3m 6s\n",
            "423:\ttotal: 50s\tremaining: 3m 5s\n",
            "424:\ttotal: 50.1s\tremaining: 3m 5s\n",
            "425:\ttotal: 50.2s\tremaining: 3m 5s\n",
            "426:\ttotal: 50.3s\tremaining: 3m 5s\n",
            "427:\ttotal: 50.4s\tremaining: 3m 5s\n",
            "428:\ttotal: 50.6s\tremaining: 3m 5s\n",
            "429:\ttotal: 50.8s\tremaining: 3m 5s\n",
            "430:\ttotal: 51.1s\tremaining: 3m 6s\n",
            "431:\ttotal: 51.2s\tremaining: 3m 5s\n",
            "432:\ttotal: 51.3s\tremaining: 3m 5s\n",
            "433:\ttotal: 51.4s\tremaining: 3m 5s\n",
            "434:\ttotal: 51.4s\tremaining: 3m 5s\n",
            "435:\ttotal: 51.5s\tremaining: 3m 4s\n",
            "436:\ttotal: 51.6s\tremaining: 3m 4s\n",
            "437:\ttotal: 51.8s\tremaining: 3m 4s\n",
            "438:\ttotal: 51.9s\tremaining: 3m 4s\n",
            "439:\ttotal: 51.9s\tremaining: 3m 4s\n",
            "440:\ttotal: 52s\tremaining: 3m 3s\n",
            "441:\ttotal: 52.1s\tremaining: 3m 3s\n",
            "442:\ttotal: 52.1s\tremaining: 3m 3s\n",
            "443:\ttotal: 52.2s\tremaining: 3m 2s\n",
            "444:\ttotal: 52.3s\tremaining: 3m 2s\n",
            "445:\ttotal: 52.4s\tremaining: 3m 2s\n",
            "446:\ttotal: 52.5s\tremaining: 3m 2s\n",
            "447:\ttotal: 52.6s\tremaining: 3m 2s\n",
            "448:\ttotal: 52.9s\tremaining: 3m 2s\n",
            "449:\ttotal: 53s\tremaining: 3m 2s\n",
            "450:\ttotal: 53.2s\tremaining: 3m 2s\n",
            "451:\ttotal: 53.4s\tremaining: 3m 2s\n",
            "452:\ttotal: 53.5s\tremaining: 3m 2s\n",
            "453:\ttotal: 53.7s\tremaining: 3m 2s\n",
            "454:\ttotal: 53.8s\tremaining: 3m 2s\n",
            "455:\ttotal: 53.8s\tremaining: 3m 2s\n",
            "456:\ttotal: 53.9s\tremaining: 3m 2s\n",
            "457:\ttotal: 54s\tremaining: 3m 1s\n",
            "458:\ttotal: 54s\tremaining: 3m 1s\n",
            "459:\ttotal: 54.1s\tremaining: 3m 1s\n",
            "460:\ttotal: 54.2s\tremaining: 3m\n",
            "461:\ttotal: 54.3s\tremaining: 3m\n",
            "462:\ttotal: 54.4s\tremaining: 3m\n",
            "463:\ttotal: 54.5s\tremaining: 3m\n",
            "464:\ttotal: 54.6s\tremaining: 3m\n",
            "465:\ttotal: 54.6s\tremaining: 2m 59s\n",
            "466:\ttotal: 54.7s\tremaining: 2m 59s\n",
            "467:\ttotal: 54.8s\tremaining: 2m 59s\n",
            "468:\ttotal: 54.8s\tremaining: 2m 58s\n",
            "469:\ttotal: 54.9s\tremaining: 2m 58s\n",
            "470:\ttotal: 55s\tremaining: 2m 58s\n",
            "471:\ttotal: 55.1s\tremaining: 2m 58s\n",
            "472:\ttotal: 55.1s\tremaining: 2m 57s\n",
            "473:\ttotal: 55.2s\tremaining: 2m 57s\n",
            "474:\ttotal: 55.3s\tremaining: 2m 57s\n",
            "475:\ttotal: 55.4s\tremaining: 2m 57s\n",
            "476:\ttotal: 55.5s\tremaining: 2m 57s\n",
            "477:\ttotal: 55.9s\tremaining: 2m 58s\n",
            "478:\ttotal: 56.1s\tremaining: 2m 58s\n",
            "479:\ttotal: 56.2s\tremaining: 2m 57s\n",
            "480:\ttotal: 56.2s\tremaining: 2m 57s\n",
            "481:\ttotal: 56.3s\tremaining: 2m 57s\n",
            "482:\ttotal: 56.5s\tremaining: 2m 57s\n",
            "483:\ttotal: 56.6s\tremaining: 2m 57s\n",
            "484:\ttotal: 56.8s\tremaining: 2m 57s\n",
            "485:\ttotal: 56.9s\tremaining: 2m 57s\n",
            "486:\ttotal: 57s\tremaining: 2m 57s\n",
            "487:\ttotal: 57.1s\tremaining: 2m 56s\n",
            "488:\ttotal: 57.1s\tremaining: 2m 56s\n",
            "489:\ttotal: 57.2s\tremaining: 2m 56s\n",
            "490:\ttotal: 57.3s\tremaining: 2m 56s\n",
            "491:\ttotal: 57.3s\tremaining: 2m 55s\n",
            "492:\ttotal: 57.4s\tremaining: 2m 55s\n",
            "493:\ttotal: 57.5s\tremaining: 2m 55s\n",
            "494:\ttotal: 57.5s\tremaining: 2m 54s\n",
            "495:\ttotal: 57.6s\tremaining: 2m 54s\n",
            "496:\ttotal: 57.6s\tremaining: 2m 54s\n",
            "497:\ttotal: 57.7s\tremaining: 2m 54s\n",
            "498:\ttotal: 57.8s\tremaining: 2m 53s\n",
            "499:\ttotal: 57.8s\tremaining: 2m 53s\n",
            "500:\ttotal: 57.9s\tremaining: 2m 53s\n",
            "501:\ttotal: 58s\tremaining: 2m 53s\n",
            "502:\ttotal: 58.1s\tremaining: 2m 52s\n",
            "503:\ttotal: 58.2s\tremaining: 2m 52s\n",
            "504:\ttotal: 58.3s\tremaining: 2m 52s\n",
            "505:\ttotal: 58.5s\tremaining: 2m 52s\n",
            "506:\ttotal: 58.6s\tremaining: 2m 52s\n",
            "507:\ttotal: 58.7s\tremaining: 2m 52s\n",
            "508:\ttotal: 58.8s\tremaining: 2m 52s\n",
            "509:\ttotal: 58.9s\tremaining: 2m 52s\n",
            "510:\ttotal: 59.1s\tremaining: 2m 52s\n",
            "511:\ttotal: 59.3s\tremaining: 2m 52s\n",
            "512:\ttotal: 59.4s\tremaining: 2m 52s\n",
            "513:\ttotal: 59.5s\tremaining: 2m 52s\n",
            "514:\ttotal: 59.6s\tremaining: 2m 51s\n",
            "515:\ttotal: 59.7s\tremaining: 2m 51s\n",
            "516:\ttotal: 59.8s\tremaining: 2m 51s\n",
            "517:\ttotal: 59.9s\tremaining: 2m 51s\n",
            "518:\ttotal: 1m\tremaining: 2m 51s\n",
            "519:\ttotal: 1m\tremaining: 2m 51s\n",
            "520:\ttotal: 1m\tremaining: 2m 50s\n",
            "521:\ttotal: 1m\tremaining: 2m 50s\n",
            "522:\ttotal: 1m\tremaining: 2m 50s\n",
            "523:\ttotal: 1m\tremaining: 2m 50s\n",
            "524:\ttotal: 1m\tremaining: 2m 50s\n",
            "525:\ttotal: 1m\tremaining: 2m 50s\n",
            "526:\ttotal: 1m\tremaining: 2m 50s\n",
            "527:\ttotal: 1m 1s\tremaining: 2m 50s\n",
            "528:\ttotal: 1m 1s\tremaining: 2m 50s\n",
            "529:\ttotal: 1m 1s\tremaining: 2m 50s\n",
            "530:\ttotal: 1m 1s\tremaining: 2m 50s\n",
            "531:\ttotal: 1m 1s\tremaining: 2m 49s\n",
            "532:\ttotal: 1m 1s\tremaining: 2m 49s\n",
            "533:\ttotal: 1m 1s\tremaining: 2m 49s\n",
            "534:\ttotal: 1m 1s\tremaining: 2m 49s\n",
            "535:\ttotal: 1m 1s\tremaining: 2m 49s\n",
            "536:\ttotal: 1m 1s\tremaining: 2m 48s\n",
            "537:\ttotal: 1m 2s\tremaining: 2m 48s\n",
            "538:\ttotal: 1m 2s\tremaining: 2m 48s\n",
            "539:\ttotal: 1m 2s\tremaining: 2m 48s\n",
            "540:\ttotal: 1m 2s\tremaining: 2m 47s\n",
            "541:\ttotal: 1m 2s\tremaining: 2m 47s\n",
            "542:\ttotal: 1m 2s\tremaining: 2m 47s\n",
            "543:\ttotal: 1m 2s\tremaining: 2m 47s\n",
            "544:\ttotal: 1m 2s\tremaining: 2m 46s\n",
            "545:\ttotal: 1m 2s\tremaining: 2m 46s\n",
            "546:\ttotal: 1m 2s\tremaining: 2m 46s\n",
            "547:\ttotal: 1m 2s\tremaining: 2m 46s\n",
            "548:\ttotal: 1m 2s\tremaining: 2m 45s\n",
            "549:\ttotal: 1m 2s\tremaining: 2m 45s\n",
            "550:\ttotal: 1m 2s\tremaining: 2m 45s\n",
            "551:\ttotal: 1m 2s\tremaining: 2m 45s\n",
            "552:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "553:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "554:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "555:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "556:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "557:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "558:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "559:\ttotal: 1m 3s\tremaining: 2m 44s\n",
            "560:\ttotal: 1m 3s\tremaining: 2m 43s\n",
            "561:\ttotal: 1m 3s\tremaining: 2m 43s\n",
            "562:\ttotal: 1m 4s\tremaining: 2m 43s\n",
            "563:\ttotal: 1m 4s\tremaining: 2m 43s\n",
            "564:\ttotal: 1m 4s\tremaining: 2m 43s\n",
            "565:\ttotal: 1m 4s\tremaining: 2m 43s\n",
            "566:\ttotal: 1m 4s\tremaining: 2m 43s\n",
            "567:\ttotal: 1m 4s\tremaining: 2m 42s\n",
            "568:\ttotal: 1m 4s\tremaining: 2m 42s\n",
            "569:\ttotal: 1m 4s\tremaining: 2m 42s\n",
            "570:\ttotal: 1m 4s\tremaining: 2m 42s\n",
            "571:\ttotal: 1m 5s\tremaining: 2m 42s\n",
            "572:\ttotal: 1m 5s\tremaining: 2m 42s\n",
            "573:\ttotal: 1m 5s\tremaining: 2m 41s\n",
            "574:\ttotal: 1m 5s\tremaining: 2m 41s\n",
            "575:\ttotal: 1m 5s\tremaining: 2m 41s\n",
            "576:\ttotal: 1m 5s\tremaining: 2m 41s\n",
            "577:\ttotal: 1m 5s\tremaining: 2m 40s\n",
            "578:\ttotal: 1m 5s\tremaining: 2m 40s\n",
            "579:\ttotal: 1m 5s\tremaining: 2m 41s\n",
            "580:\ttotal: 1m 5s\tremaining: 2m 40s\n",
            "581:\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "582:\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "583:\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "584:\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "585:\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "586:\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "587:\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "588:\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "589:\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "590:\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "591:\ttotal: 1m 7s\tremaining: 2m 39s\n",
            "592:\ttotal: 1m 7s\tremaining: 2m 39s\n",
            "593:\ttotal: 1m 7s\tremaining: 2m 39s\n",
            "594:\ttotal: 1m 7s\tremaining: 2m 39s\n",
            "595:\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "596:\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "597:\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "598:\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "599:\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "600:\ttotal: 1m 8s\tremaining: 2m 38s\n",
            "601:\ttotal: 1m 8s\tremaining: 2m 38s\n",
            "602:\ttotal: 1m 8s\tremaining: 2m 38s\n",
            "603:\ttotal: 1m 8s\tremaining: 2m 38s\n",
            "604:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "605:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "606:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "607:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "608:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "609:\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "610:\ttotal: 1m 9s\tremaining: 2m 37s\n",
            "611:\ttotal: 1m 9s\tremaining: 2m 36s\n",
            "612:\ttotal: 1m 9s\tremaining: 2m 36s\n",
            "613:\ttotal: 1m 9s\tremaining: 2m 36s\n",
            "614:\ttotal: 1m 9s\tremaining: 2m 36s\n",
            "615:\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "616:\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "617:\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "618:\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "619:\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "620:\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "621:\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "622:\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "623:\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "624:\ttotal: 1m 10s\tremaining: 2m 34s\n",
            "625:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "626:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "627:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "628:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "629:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "630:\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "631:\ttotal: 1m 10s\tremaining: 2m 32s\n",
            "632:\ttotal: 1m 10s\tremaining: 2m 32s\n",
            "633:\ttotal: 1m 10s\tremaining: 2m 32s\n",
            "634:\ttotal: 1m 10s\tremaining: 2m 32s\n",
            "635:\ttotal: 1m 10s\tremaining: 2m 31s\n",
            "636:\ttotal: 1m 10s\tremaining: 2m 31s\n",
            "637:\ttotal: 1m 10s\tremaining: 2m 31s\n",
            "638:\ttotal: 1m 11s\tremaining: 2m 31s\n",
            "639:\ttotal: 1m 11s\tremaining: 2m 31s\n",
            "640:\ttotal: 1m 11s\tremaining: 2m 30s\n",
            "641:\ttotal: 1m 11s\tremaining: 2m 30s\n",
            "642:\ttotal: 1m 11s\tremaining: 2m 30s\n",
            "643:\ttotal: 1m 11s\tremaining: 2m 30s\n",
            "644:\ttotal: 1m 11s\tremaining: 2m 30s\n",
            "645:\ttotal: 1m 11s\tremaining: 2m 29s\n",
            "646:\ttotal: 1m 11s\tremaining: 2m 29s\n",
            "647:\ttotal: 1m 11s\tremaining: 2m 29s\n",
            "648:\ttotal: 1m 11s\tremaining: 2m 29s\n",
            "649:\ttotal: 1m 11s\tremaining: 2m 29s\n",
            "650:\ttotal: 1m 12s\tremaining: 2m 29s\n",
            "651:\ttotal: 1m 12s\tremaining: 2m 29s\n",
            "652:\ttotal: 1m 12s\tremaining: 2m 29s\n",
            "653:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "654:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "655:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "656:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "657:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "658:\ttotal: 1m 12s\tremaining: 2m 28s\n",
            "659:\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "660:\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "661:\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "662:\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "663:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "664:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "665:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "666:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "667:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "668:\ttotal: 1m 13s\tremaining: 2m 27s\n",
            "669:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "670:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "671:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "672:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "673:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "674:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "675:\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "676:\ttotal: 1m 14s\tremaining: 2m 25s\n",
            "677:\ttotal: 1m 14s\tremaining: 2m 25s\n",
            "678:\ttotal: 1m 14s\tremaining: 2m 25s\n",
            "679:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "680:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "681:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "682:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "683:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "684:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "685:\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "686:\ttotal: 1m 15s\tremaining: 2m 24s\n",
            "687:\ttotal: 1m 15s\tremaining: 2m 24s\n",
            "688:\ttotal: 1m 16s\tremaining: 2m 24s\n",
            "689:\ttotal: 1m 16s\tremaining: 2m 24s\n",
            "690:\ttotal: 1m 16s\tremaining: 2m 24s\n",
            "691:\ttotal: 1m 16s\tremaining: 2m 24s\n",
            "692:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "693:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "694:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "695:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "696:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "697:\ttotal: 1m 16s\tremaining: 2m 23s\n",
            "698:\ttotal: 1m 16s\tremaining: 2m 22s\n",
            "699:\ttotal: 1m 16s\tremaining: 2m 22s\n",
            "700:\ttotal: 1m 16s\tremaining: 2m 22s\n",
            "701:\ttotal: 1m 16s\tremaining: 2m 22s\n",
            "702:\ttotal: 1m 17s\tremaining: 2m 22s\n",
            "703:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "704:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "705:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "706:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "707:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "708:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "709:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "710:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "711:\ttotal: 1m 17s\tremaining: 2m 21s\n",
            "712:\ttotal: 1m 18s\tremaining: 2m 21s\n",
            "713:\ttotal: 1m 18s\tremaining: 2m 21s\n",
            "714:\ttotal: 1m 18s\tremaining: 2m 21s\n",
            "715:\ttotal: 1m 18s\tremaining: 2m 21s\n",
            "716:\ttotal: 1m 18s\tremaining: 2m 21s\n",
            "717:\ttotal: 1m 18s\tremaining: 2m 20s\n",
            "718:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "719:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "720:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "721:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "722:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "723:\ttotal: 1m 19s\tremaining: 2m 20s\n",
            "724:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "725:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "726:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "727:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "728:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "729:\ttotal: 1m 19s\tremaining: 2m 19s\n",
            "730:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "731:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "732:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "733:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "734:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "735:\ttotal: 1m 20s\tremaining: 2m 18s\n",
            "736:\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "737:\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "738:\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "739:\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "740:\ttotal: 1m 20s\tremaining: 2m 17s\n",
            "741:\ttotal: 1m 21s\tremaining: 2m 17s\n",
            "742:\ttotal: 1m 21s\tremaining: 2m 17s\n",
            "743:\ttotal: 1m 21s\tremaining: 2m 17s\n",
            "744:\ttotal: 1m 21s\tremaining: 2m 17s\n",
            "745:\ttotal: 1m 21s\tremaining: 2m 16s\n",
            "746:\ttotal: 1m 21s\tremaining: 2m 16s\n",
            "747:\ttotal: 1m 21s\tremaining: 2m 16s\n",
            "748:\ttotal: 1m 22s\tremaining: 2m 17s\n",
            "749:\ttotal: 1m 22s\tremaining: 2m 17s\n",
            "750:\ttotal: 1m 22s\tremaining: 2m 16s\n",
            "751:\ttotal: 1m 22s\tremaining: 2m 16s\n",
            "752:\ttotal: 1m 22s\tremaining: 2m 16s\n",
            "753:\ttotal: 1m 22s\tremaining: 2m 16s\n",
            "754:\ttotal: 1m 22s\tremaining: 2m 16s\n",
            "755:\ttotal: 1m 22s\tremaining: 2m 15s\n",
            "756:\ttotal: 1m 22s\tremaining: 2m 15s\n",
            "757:\ttotal: 1m 22s\tremaining: 2m 15s\n",
            "758:\ttotal: 1m 22s\tremaining: 2m 15s\n",
            "759:\ttotal: 1m 22s\tremaining: 2m 15s\n",
            "760:\ttotal: 1m 23s\tremaining: 2m 15s\n",
            "761:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "762:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "763:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "764:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "765:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "766:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "767:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "768:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "769:\ttotal: 1m 23s\tremaining: 2m 14s\n",
            "770:\ttotal: 1m 24s\tremaining: 2m 14s\n",
            "771:\ttotal: 1m 24s\tremaining: 2m 14s\n",
            "772:\ttotal: 1m 24s\tremaining: 2m 14s\n",
            "773:\ttotal: 1m 24s\tremaining: 2m 14s\n",
            "774:\ttotal: 1m 24s\tremaining: 2m 13s\n",
            "775:\ttotal: 1m 24s\tremaining: 2m 13s\n",
            "776:\ttotal: 1m 24s\tremaining: 2m 13s\n",
            "777:\ttotal: 1m 24s\tremaining: 2m 13s\n",
            "778:\ttotal: 1m 25s\tremaining: 2m 13s\n",
            "779:\ttotal: 1m 25s\tremaining: 2m 13s\n",
            "780:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "781:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "782:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "783:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "784:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "785:\ttotal: 1m 25s\tremaining: 2m 12s\n",
            "786:\ttotal: 1m 25s\tremaining: 2m 11s\n",
            "787:\ttotal: 1m 25s\tremaining: 2m 11s\n",
            "788:\ttotal: 1m 25s\tremaining: 2m 11s\n",
            "789:\ttotal: 1m 25s\tremaining: 2m 11s\n",
            "790:\ttotal: 1m 25s\tremaining: 2m 11s\n",
            "791:\ttotal: 1m 26s\tremaining: 2m 11s\n",
            "792:\ttotal: 1m 26s\tremaining: 2m 11s\n",
            "793:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "794:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "795:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "796:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "797:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "798:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "799:\ttotal: 1m 26s\tremaining: 2m 10s\n",
            "800:\ttotal: 1m 26s\tremaining: 2m 9s\n",
            "801:\ttotal: 1m 26s\tremaining: 2m 9s\n",
            "802:\ttotal: 1m 26s\tremaining: 2m 9s\n",
            "803:\ttotal: 1m 26s\tremaining: 2m 9s\n",
            "804:\ttotal: 1m 27s\tremaining: 2m 9s\n",
            "805:\ttotal: 1m 27s\tremaining: 2m 9s\n",
            "806:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "807:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "808:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "809:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "810:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "811:\ttotal: 1m 27s\tremaining: 2m 8s\n",
            "812:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "813:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "814:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "815:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "816:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "817:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "818:\ttotal: 1m 28s\tremaining: 2m 8s\n",
            "819:\ttotal: 1m 28s\tremaining: 2m 7s\n",
            "820:\ttotal: 1m 28s\tremaining: 2m 7s\n",
            "821:\ttotal: 1m 29s\tremaining: 2m 7s\n",
            "822:\ttotal: 1m 29s\tremaining: 2m 7s\n",
            "823:\ttotal: 1m 29s\tremaining: 2m 7s\n",
            "824:\ttotal: 1m 29s\tremaining: 2m 7s\n",
            "825:\ttotal: 1m 29s\tremaining: 2m 7s\n",
            "826:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "827:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "828:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "829:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "830:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "831:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "832:\ttotal: 1m 29s\tremaining: 2m 6s\n",
            "833:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "834:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "835:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "836:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "837:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "838:\ttotal: 1m 30s\tremaining: 2m 5s\n",
            "839:\ttotal: 1m 30s\tremaining: 2m 4s\n",
            "840:\ttotal: 1m 30s\tremaining: 2m 4s\n",
            "841:\ttotal: 1m 30s\tremaining: 2m 4s\n",
            "842:\ttotal: 1m 30s\tremaining: 2m 4s\n",
            "843:\ttotal: 1m 30s\tremaining: 2m 4s\n",
            "844:\ttotal: 1m 31s\tremaining: 2m 4s\n",
            "845:\ttotal: 1m 31s\tremaining: 2m 4s\n",
            "846:\ttotal: 1m 31s\tremaining: 2m 4s\n",
            "847:\ttotal: 1m 31s\tremaining: 2m 4s\n",
            "848:\ttotal: 1m 31s\tremaining: 2m 3s\n",
            "849:\ttotal: 1m 31s\tremaining: 2m 3s\n",
            "850:\ttotal: 1m 31s\tremaining: 2m 3s\n",
            "851:\ttotal: 1m 31s\tremaining: 2m 3s\n",
            "852:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "853:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "854:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "855:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "856:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "857:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "858:\ttotal: 1m 32s\tremaining: 2m 2s\n",
            "859:\ttotal: 1m 32s\tremaining: 2m 3s\n",
            "860:\ttotal: 1m 32s\tremaining: 2m 2s\n",
            "861:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "862:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "863:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "864:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "865:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "866:\ttotal: 1m 33s\tremaining: 2m 2s\n",
            "867:\ttotal: 1m 33s\tremaining: 2m 1s\n",
            "868:\ttotal: 1m 33s\tremaining: 2m 1s\n",
            "869:\ttotal: 1m 33s\tremaining: 2m 1s\n",
            "870:\ttotal: 1m 33s\tremaining: 2m 1s\n",
            "871:\ttotal: 1m 33s\tremaining: 2m 1s\n",
            "872:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "873:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "874:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "875:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "876:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "877:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "878:\ttotal: 1m 34s\tremaining: 2m 1s\n",
            "879:\ttotal: 1m 35s\tremaining: 2m 1s\n",
            "880:\ttotal: 1m 35s\tremaining: 2m\n",
            "881:\ttotal: 1m 35s\tremaining: 2m\n",
            "882:\ttotal: 1m 35s\tremaining: 2m\n",
            "883:\ttotal: 1m 35s\tremaining: 2m\n",
            "884:\ttotal: 1m 35s\tremaining: 2m\n",
            "885:\ttotal: 1m 35s\tremaining: 2m\n",
            "886:\ttotal: 1m 35s\tremaining: 2m\n",
            "887:\ttotal: 1m 36s\tremaining: 2m\n",
            "888:\ttotal: 1m 36s\tremaining: 2m\n",
            "889:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "890:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "891:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "892:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "893:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "894:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "895:\ttotal: 1m 36s\tremaining: 1m 59s\n",
            "896:\ttotal: 1m 36s\tremaining: 1m 58s\n",
            "897:\ttotal: 1m 37s\tremaining: 1m 59s\n",
            "898:\ttotal: 1m 37s\tremaining: 1m 59s\n",
            "899:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "900:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "901:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "902:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "903:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "904:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "905:\ttotal: 1m 37s\tremaining: 1m 58s\n",
            "906:\ttotal: 1m 37s\tremaining: 1m 57s\n",
            "907:\ttotal: 1m 37s\tremaining: 1m 57s\n",
            "908:\ttotal: 1m 38s\tremaining: 1m 57s\n",
            "909:\ttotal: 1m 38s\tremaining: 1m 57s\n",
            "910:\ttotal: 1m 38s\tremaining: 1m 57s\n",
            "911:\ttotal: 1m 38s\tremaining: 1m 57s\n",
            "912:\ttotal: 1m 38s\tremaining: 1m 57s\n",
            "913:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "914:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "915:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "916:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "917:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "918:\ttotal: 1m 38s\tremaining: 1m 56s\n",
            "919:\ttotal: 1m 38s\tremaining: 1m 55s\n",
            "920:\ttotal: 1m 38s\tremaining: 1m 55s\n",
            "921:\ttotal: 1m 38s\tremaining: 1m 55s\n",
            "922:\ttotal: 1m 38s\tremaining: 1m 55s\n",
            "923:\ttotal: 1m 39s\tremaining: 1m 55s\n",
            "924:\ttotal: 1m 39s\tremaining: 1m 55s\n",
            "925:\ttotal: 1m 39s\tremaining: 1m 55s\n",
            "926:\ttotal: 1m 39s\tremaining: 1m 55s\n",
            "927:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "928:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "929:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "930:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "931:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "932:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "933:\ttotal: 1m 39s\tremaining: 1m 54s\n",
            "934:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "935:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "936:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "937:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "938:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "939:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "940:\ttotal: 1m 40s\tremaining: 1m 53s\n",
            "941:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "942:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "943:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "944:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "945:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "946:\ttotal: 1m 40s\tremaining: 1m 52s\n",
            "947:\ttotal: 1m 40s\tremaining: 1m 51s\n",
            "948:\ttotal: 1m 40s\tremaining: 1m 51s\n",
            "949:\ttotal: 1m 41s\tremaining: 1m 51s\n",
            "950:\ttotal: 1m 41s\tremaining: 1m 51s\n",
            "951:\ttotal: 1m 41s\tremaining: 1m 51s\n",
            "952:\ttotal: 1m 41s\tremaining: 1m 51s\n",
            "953:\ttotal: 1m 41s\tremaining: 1m 51s\n",
            "954:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "955:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "956:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "957:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "958:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "959:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "960:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "961:\ttotal: 1m 41s\tremaining: 1m 50s\n",
            "962:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "963:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "964:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "965:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "966:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "967:\ttotal: 1m 42s\tremaining: 1m 49s\n",
            "968:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "969:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "970:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "971:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "972:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "973:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "974:\ttotal: 1m 42s\tremaining: 1m 48s\n",
            "975:\ttotal: 1m 42s\tremaining: 1m 47s\n",
            "976:\ttotal: 1m 42s\tremaining: 1m 47s\n",
            "977:\ttotal: 1m 42s\tremaining: 1m 47s\n",
            "978:\ttotal: 1m 43s\tremaining: 1m 47s\n",
            "979:\ttotal: 1m 43s\tremaining: 1m 47s\n",
            "980:\ttotal: 1m 43s\tremaining: 1m 47s\n",
            "981:\ttotal: 1m 43s\tremaining: 1m 47s\n",
            "982:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "983:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "984:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "985:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "986:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "987:\ttotal: 1m 43s\tremaining: 1m 46s\n",
            "988:\ttotal: 1m 43s\tremaining: 1m 45s\n",
            "989:\ttotal: 1m 43s\tremaining: 1m 45s\n",
            "990:\ttotal: 1m 43s\tremaining: 1m 45s\n",
            "991:\ttotal: 1m 43s\tremaining: 1m 45s\n",
            "992:\ttotal: 1m 43s\tremaining: 1m 45s\n",
            "993:\ttotal: 1m 44s\tremaining: 1m 45s\n",
            "994:\ttotal: 1m 44s\tremaining: 1m 45s\n",
            "995:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "996:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "997:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "998:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "999:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "1000:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "1001:\ttotal: 1m 44s\tremaining: 1m 44s\n",
            "1002:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1003:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1004:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1005:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1006:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1007:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1008:\ttotal: 1m 44s\tremaining: 1m 43s\n",
            "1009:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1010:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1011:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1012:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1013:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1014:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1015:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1016:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1017:\ttotal: 1m 45s\tremaining: 1m 42s\n",
            "1018:\ttotal: 1m 45s\tremaining: 1m 41s\n",
            "1019:\ttotal: 1m 45s\tremaining: 1m 41s\n",
            "1020:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1021:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1022:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1023:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1024:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1025:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1026:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1027:\ttotal: 1m 46s\tremaining: 1m 41s\n",
            "1028:\ttotal: 1m 47s\tremaining: 1m 41s\n",
            "1029:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1030:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1031:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1032:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1033:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1034:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1035:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1036:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1037:\ttotal: 1m 47s\tremaining: 1m 40s\n",
            "1038:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1039:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1040:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1041:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1042:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1043:\ttotal: 1m 48s\tremaining: 1m 39s\n",
            "1044:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1045:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1046:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1047:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1048:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1049:\ttotal: 1m 49s\tremaining: 1m 39s\n",
            "1050:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1051:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1052:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1053:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1054:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1055:\ttotal: 1m 49s\tremaining: 1m 38s\n",
            "1056:\ttotal: 1m 50s\tremaining: 1m 38s\n",
            "1057:\ttotal: 1m 50s\tremaining: 1m 38s\n",
            "1058:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1059:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1060:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1061:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1062:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1063:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1064:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1065:\ttotal: 1m 50s\tremaining: 1m 37s\n",
            "1066:\ttotal: 1m 51s\tremaining: 1m 37s\n",
            "1067:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1068:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1069:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1070:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1071:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1072:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1073:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1074:\ttotal: 1m 51s\tremaining: 1m 36s\n",
            "1075:\ttotal: 1m 52s\tremaining: 1m 36s\n",
            "1076:\ttotal: 1m 52s\tremaining: 1m 36s\n",
            "1077:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1078:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1079:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1080:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1081:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1082:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1083:\ttotal: 1m 52s\tremaining: 1m 35s\n",
            "1084:\ttotal: 1m 52s\tremaining: 1m 34s\n",
            "1085:\ttotal: 1m 52s\tremaining: 1m 34s\n",
            "1086:\ttotal: 1m 52s\tremaining: 1m 34s\n",
            "1087:\ttotal: 1m 52s\tremaining: 1m 34s\n",
            "1088:\ttotal: 1m 52s\tremaining: 1m 34s\n",
            "1089:\ttotal: 1m 53s\tremaining: 1m 34s\n",
            "1090:\ttotal: 1m 53s\tremaining: 1m 34s\n",
            "1091:\ttotal: 1m 53s\tremaining: 1m 34s\n",
            "1092:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1093:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1094:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1095:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1096:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1097:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1098:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1099:\ttotal: 1m 53s\tremaining: 1m 33s\n",
            "1100:\ttotal: 1m 53s\tremaining: 1m 32s\n",
            "1101:\ttotal: 1m 53s\tremaining: 1m 32s\n",
            "1102:\ttotal: 1m 53s\tremaining: 1m 32s\n",
            "1103:\ttotal: 1m 53s\tremaining: 1m 32s\n",
            "1104:\ttotal: 1m 54s\tremaining: 1m 32s\n",
            "1105:\ttotal: 1m 54s\tremaining: 1m 32s\n",
            "1106:\ttotal: 1m 54s\tremaining: 1m 32s\n",
            "1107:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1108:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1109:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1110:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1111:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1112:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1113:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1114:\ttotal: 1m 54s\tremaining: 1m 31s\n",
            "1115:\ttotal: 1m 54s\tremaining: 1m 30s\n",
            "1116:\ttotal: 1m 54s\tremaining: 1m 30s\n",
            "1117:\ttotal: 1m 54s\tremaining: 1m 30s\n",
            "1118:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1119:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1120:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1121:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1122:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1123:\ttotal: 1m 55s\tremaining: 1m 30s\n",
            "1124:\ttotal: 1m 55s\tremaining: 1m 29s\n",
            "1125:\ttotal: 1m 55s\tremaining: 1m 29s\n",
            "1126:\ttotal: 1m 55s\tremaining: 1m 29s\n",
            "1127:\ttotal: 1m 55s\tremaining: 1m 29s\n",
            "1128:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1129:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1130:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1131:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1132:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1133:\ttotal: 1m 56s\tremaining: 1m 29s\n",
            "1134:\ttotal: 1m 56s\tremaining: 1m 28s\n",
            "1135:\ttotal: 1m 56s\tremaining: 1m 28s\n",
            "1136:\ttotal: 1m 56s\tremaining: 1m 28s\n",
            "1137:\ttotal: 1m 56s\tremaining: 1m 28s\n",
            "1138:\ttotal: 1m 57s\tremaining: 1m 28s\n",
            "1139:\ttotal: 1m 57s\tremaining: 1m 28s\n",
            "1140:\ttotal: 1m 57s\tremaining: 1m 28s\n",
            "1141:\ttotal: 1m 57s\tremaining: 1m 28s\n",
            "1142:\ttotal: 1m 57s\tremaining: 1m 28s\n",
            "1143:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1144:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1145:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1146:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1147:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1148:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1149:\ttotal: 1m 57s\tremaining: 1m 27s\n",
            "1150:\ttotal: 1m 57s\tremaining: 1m 26s\n",
            "1151:\ttotal: 1m 57s\tremaining: 1m 26s\n",
            "1152:\ttotal: 1m 57s\tremaining: 1m 26s\n",
            "1153:\ttotal: 1m 58s\tremaining: 1m 26s\n",
            "1154:\ttotal: 1m 58s\tremaining: 1m 26s\n",
            "1155:\ttotal: 1m 58s\tremaining: 1m 26s\n",
            "1156:\ttotal: 1m 58s\tremaining: 1m 26s\n",
            "1157:\ttotal: 1m 58s\tremaining: 1m 26s\n",
            "1158:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1159:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1160:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1161:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1162:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1163:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1164:\ttotal: 1m 58s\tremaining: 1m 25s\n",
            "1165:\ttotal: 1m 58s\tremaining: 1m 24s\n",
            "1166:\ttotal: 1m 58s\tremaining: 1m 24s\n",
            "1167:\ttotal: 1m 58s\tremaining: 1m 24s\n",
            "1168:\ttotal: 1m 59s\tremaining: 1m 24s\n",
            "1169:\ttotal: 1m 59s\tremaining: 1m 24s\n",
            "1170:\ttotal: 1m 59s\tremaining: 1m 24s\n",
            "1171:\ttotal: 1m 59s\tremaining: 1m 24s\n",
            "1172:\ttotal: 1m 59s\tremaining: 1m 24s\n",
            "1173:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1174:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1175:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1176:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1177:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1178:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1179:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1180:\ttotal: 1m 59s\tremaining: 1m 23s\n",
            "1181:\ttotal: 2m\tremaining: 1m 23s\n",
            "1182:\ttotal: 2m\tremaining: 1m 22s\n",
            "1183:\ttotal: 2m\tremaining: 1m 22s\n",
            "1184:\ttotal: 2m\tremaining: 1m 22s\n",
            "1185:\ttotal: 2m\tremaining: 1m 22s\n",
            "1186:\ttotal: 2m\tremaining: 1m 22s\n",
            "1187:\ttotal: 2m\tremaining: 1m 22s\n",
            "1188:\ttotal: 2m\tremaining: 1m 22s\n",
            "1189:\ttotal: 2m\tremaining: 1m 22s\n",
            "1190:\ttotal: 2m\tremaining: 1m 21s\n",
            "1191:\ttotal: 2m\tremaining: 1m 21s\n",
            "1192:\ttotal: 2m\tremaining: 1m 21s\n",
            "1193:\ttotal: 2m\tremaining: 1m 21s\n",
            "1194:\ttotal: 2m\tremaining: 1m 21s\n",
            "1195:\ttotal: 2m 1s\tremaining: 1m 21s\n",
            "1196:\ttotal: 2m 1s\tremaining: 1m 21s\n",
            "1197:\ttotal: 2m 1s\tremaining: 1m 21s\n",
            "1198:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1199:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1200:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1201:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1202:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1203:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1204:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1205:\ttotal: 2m 1s\tremaining: 1m 20s\n",
            "1206:\ttotal: 2m 1s\tremaining: 1m 19s\n",
            "1207:\ttotal: 2m 1s\tremaining: 1m 19s\n",
            "1208:\ttotal: 2m 1s\tremaining: 1m 19s\n",
            "1209:\ttotal: 2m 1s\tremaining: 1m 19s\n",
            "1210:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1211:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1212:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1213:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1214:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1215:\ttotal: 2m 2s\tremaining: 1m 19s\n",
            "1216:\ttotal: 2m 2s\tremaining: 1m 18s\n",
            "1217:\ttotal: 2m 2s\tremaining: 1m 18s\n",
            "1218:\ttotal: 2m 3s\tremaining: 1m 18s\n",
            "1219:\ttotal: 2m 3s\tremaining: 1m 18s\n",
            "1220:\ttotal: 2m 3s\tremaining: 1m 18s\n",
            "1221:\ttotal: 2m 3s\tremaining: 1m 18s\n",
            "1222:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1223:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1224:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1225:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1226:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1227:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1228:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1229:\ttotal: 2m 4s\tremaining: 1m 18s\n",
            "1230:\ttotal: 2m 5s\tremaining: 1m 18s\n",
            "1231:\ttotal: 2m 5s\tremaining: 1m 18s\n",
            "1232:\ttotal: 2m 5s\tremaining: 1m 18s\n",
            "1233:\ttotal: 2m 5s\tremaining: 1m 17s\n",
            "1234:\ttotal: 2m 5s\tremaining: 1m 17s\n",
            "1235:\ttotal: 2m 5s\tremaining: 1m 17s\n",
            "1236:\ttotal: 2m 5s\tremaining: 1m 17s\n",
            "1237:\ttotal: 2m 6s\tremaining: 1m 17s\n",
            "1238:\ttotal: 2m 6s\tremaining: 1m 17s\n",
            "1239:\ttotal: 2m 6s\tremaining: 1m 17s\n",
            "1240:\ttotal: 2m 6s\tremaining: 1m 17s\n",
            "1241:\ttotal: 2m 6s\tremaining: 1m 17s\n",
            "1242:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1243:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1244:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1245:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1246:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1247:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1248:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1249:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1250:\ttotal: 2m 6s\tremaining: 1m 16s\n",
            "1251:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1252:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1253:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1254:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1255:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1256:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1257:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1258:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1259:\ttotal: 2m 7s\tremaining: 1m 15s\n",
            "1260:\ttotal: 2m 7s\tremaining: 1m 14s\n",
            "1261:\ttotal: 2m 7s\tremaining: 1m 14s\n",
            "1262:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1263:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1264:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1265:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1266:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1267:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1268:\ttotal: 2m 8s\tremaining: 1m 14s\n",
            "1269:\ttotal: 2m 8s\tremaining: 1m 13s\n",
            "1270:\ttotal: 2m 8s\tremaining: 1m 13s\n",
            "1271:\ttotal: 2m 8s\tremaining: 1m 13s\n",
            "1272:\ttotal: 2m 8s\tremaining: 1m 13s\n",
            "1273:\ttotal: 2m 9s\tremaining: 1m 13s\n",
            "1274:\ttotal: 2m 9s\tremaining: 1m 13s\n",
            "1275:\ttotal: 2m 9s\tremaining: 1m 13s\n",
            "1276:\ttotal: 2m 9s\tremaining: 1m 13s\n",
            "1277:\ttotal: 2m 9s\tremaining: 1m 13s\n",
            "1278:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1279:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1280:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1281:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1282:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1283:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1284:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1285:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1286:\ttotal: 2m 9s\tremaining: 1m 12s\n",
            "1287:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1288:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1289:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1290:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1291:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1292:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1293:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1294:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1295:\ttotal: 2m 10s\tremaining: 1m 11s\n",
            "1296:\ttotal: 2m 11s\tremaining: 1m 11s\n",
            "1297:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1298:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1299:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1300:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1301:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1302:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1303:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1304:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1305:\ttotal: 2m 11s\tremaining: 1m 10s\n",
            "1306:\ttotal: 2m 11s\tremaining: 1m 9s\n",
            "1307:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1308:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1309:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1310:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1311:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1312:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1313:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1314:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1315:\ttotal: 2m 12s\tremaining: 1m 9s\n",
            "1316:\ttotal: 2m 12s\tremaining: 1m 8s\n",
            "1317:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1318:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1319:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1320:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1321:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1322:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1323:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1324:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1325:\ttotal: 2m 13s\tremaining: 1m 8s\n",
            "1326:\ttotal: 2m 13s\tremaining: 1m 7s\n",
            "1327:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1328:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1329:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1330:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1331:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1332:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1333:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1334:\ttotal: 2m 14s\tremaining: 1m 7s\n",
            "1335:\ttotal: 2m 14s\tremaining: 1m 6s\n",
            "1336:\ttotal: 2m 14s\tremaining: 1m 6s\n",
            "1337:\ttotal: 2m 14s\tremaining: 1m 6s\n",
            "1338:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1339:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1340:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1341:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1342:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1343:\ttotal: 2m 15s\tremaining: 1m 6s\n",
            "1344:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1345:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1346:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1347:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1348:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1349:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1350:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1351:\ttotal: 2m 15s\tremaining: 1m 5s\n",
            "1352:\ttotal: 2m 16s\tremaining: 1m 5s\n",
            "1353:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1354:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1355:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1356:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1357:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1358:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1359:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1360:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1361:\ttotal: 2m 16s\tremaining: 1m 4s\n",
            "1362:\ttotal: 2m 16s\tremaining: 1m 3s\n",
            "1363:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1364:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1365:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1366:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1367:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1368:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1369:\ttotal: 2m 17s\tremaining: 1m 3s\n",
            "1370:\ttotal: 2m 18s\tremaining: 1m 3s\n",
            "1371:\ttotal: 2m 18s\tremaining: 1m 3s\n",
            "1372:\ttotal: 2m 18s\tremaining: 1m 3s\n",
            "1373:\ttotal: 2m 18s\tremaining: 1m 3s\n",
            "1374:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1375:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1376:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1377:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1378:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1379:\ttotal: 2m 18s\tremaining: 1m 2s\n",
            "1380:\ttotal: 2m 19s\tremaining: 1m 2s\n",
            "1381:\ttotal: 2m 19s\tremaining: 1m 2s\n",
            "1382:\ttotal: 2m 19s\tremaining: 1m 2s\n",
            "1383:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1384:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1385:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1386:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1387:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1388:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1389:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1390:\ttotal: 2m 19s\tremaining: 1m 1s\n",
            "1391:\ttotal: 2m 20s\tremaining: 1m 1s\n",
            "1392:\ttotal: 2m 20s\tremaining: 1m 1s\n",
            "1393:\ttotal: 2m 20s\tremaining: 1m\n",
            "1394:\ttotal: 2m 20s\tremaining: 1m\n",
            "1395:\ttotal: 2m 20s\tremaining: 1m\n",
            "1396:\ttotal: 2m 20s\tremaining: 1m\n",
            "1397:\ttotal: 2m 20s\tremaining: 1m\n",
            "1398:\ttotal: 2m 20s\tremaining: 1m\n",
            "1399:\ttotal: 2m 20s\tremaining: 1m\n",
            "1400:\ttotal: 2m 20s\tremaining: 1m\n",
            "1401:\ttotal: 2m 20s\tremaining: 1m\n",
            "1402:\ttotal: 2m 20s\tremaining: 59.9s\n",
            "1403:\ttotal: 2m 20s\tremaining: 59.8s\n",
            "1404:\ttotal: 2m 20s\tremaining: 59.7s\n",
            "1405:\ttotal: 2m 21s\tremaining: 59.6s\n",
            "1406:\ttotal: 2m 21s\tremaining: 59.5s\n",
            "1407:\ttotal: 2m 21s\tremaining: 59.4s\n",
            "1408:\ttotal: 2m 21s\tremaining: 59.3s\n",
            "1409:\ttotal: 2m 21s\tremaining: 59.2s\n",
            "1410:\ttotal: 2m 21s\tremaining: 59.1s\n",
            "1411:\ttotal: 2m 21s\tremaining: 59s\n",
            "1412:\ttotal: 2m 21s\tremaining: 58.9s\n",
            "1413:\ttotal: 2m 21s\tremaining: 58.8s\n",
            "1414:\ttotal: 2m 21s\tremaining: 58.7s\n",
            "1415:\ttotal: 2m 22s\tremaining: 58.6s\n",
            "1416:\ttotal: 2m 22s\tremaining: 58.5s\n",
            "1417:\ttotal: 2m 22s\tremaining: 58.4s\n",
            "1418:\ttotal: 2m 22s\tremaining: 58.3s\n",
            "1419:\ttotal: 2m 22s\tremaining: 58.2s\n",
            "1420:\ttotal: 2m 22s\tremaining: 58.1s\n",
            "1421:\ttotal: 2m 22s\tremaining: 58s\n",
            "1422:\ttotal: 2m 22s\tremaining: 58s\n",
            "1423:\ttotal: 2m 23s\tremaining: 57.9s\n",
            "1424:\ttotal: 2m 23s\tremaining: 57.8s\n",
            "1425:\ttotal: 2m 23s\tremaining: 57.7s\n",
            "1426:\ttotal: 2m 23s\tremaining: 57.6s\n",
            "1427:\ttotal: 2m 23s\tremaining: 57.5s\n",
            "1428:\ttotal: 2m 23s\tremaining: 57.4s\n",
            "1429:\ttotal: 2m 23s\tremaining: 57.3s\n",
            "1430:\ttotal: 2m 23s\tremaining: 57.2s\n",
            "1431:\ttotal: 2m 23s\tremaining: 57s\n",
            "1432:\ttotal: 2m 23s\tremaining: 56.9s\n",
            "1433:\ttotal: 2m 23s\tremaining: 56.8s\n",
            "1434:\ttotal: 2m 24s\tremaining: 56.7s\n",
            "1435:\ttotal: 2m 24s\tremaining: 56.6s\n",
            "1436:\ttotal: 2m 24s\tremaining: 56.5s\n",
            "1437:\ttotal: 2m 24s\tremaining: 56.4s\n",
            "1438:\ttotal: 2m 24s\tremaining: 56.3s\n",
            "1439:\ttotal: 2m 24s\tremaining: 56.1s\n",
            "1440:\ttotal: 2m 24s\tremaining: 56s\n",
            "1441:\ttotal: 2m 24s\tremaining: 55.9s\n",
            "1442:\ttotal: 2m 24s\tremaining: 55.8s\n",
            "1443:\ttotal: 2m 24s\tremaining: 55.7s\n",
            "1444:\ttotal: 2m 24s\tremaining: 55.6s\n",
            "1445:\ttotal: 2m 24s\tremaining: 55.5s\n",
            "1446:\ttotal: 2m 24s\tremaining: 55.4s\n",
            "1447:\ttotal: 2m 25s\tremaining: 55.3s\n",
            "1448:\ttotal: 2m 25s\tremaining: 55.2s\n",
            "1449:\ttotal: 2m 25s\tremaining: 55.1s\n",
            "1450:\ttotal: 2m 25s\tremaining: 55s\n",
            "1451:\ttotal: 2m 25s\tremaining: 54.9s\n",
            "1452:\ttotal: 2m 25s\tremaining: 54.8s\n",
            "1453:\ttotal: 2m 25s\tremaining: 54.7s\n",
            "1454:\ttotal: 2m 25s\tremaining: 54.6s\n",
            "1455:\ttotal: 2m 25s\tremaining: 54.5s\n",
            "1456:\ttotal: 2m 25s\tremaining: 54.4s\n",
            "1457:\ttotal: 2m 25s\tremaining: 54.3s\n",
            "1458:\ttotal: 2m 26s\tremaining: 54.2s\n",
            "1459:\ttotal: 2m 26s\tremaining: 54.1s\n",
            "1460:\ttotal: 2m 26s\tremaining: 54s\n",
            "1461:\ttotal: 2m 26s\tremaining: 53.8s\n",
            "1462:\ttotal: 2m 26s\tremaining: 53.7s\n",
            "1463:\ttotal: 2m 26s\tremaining: 53.6s\n",
            "1464:\ttotal: 2m 26s\tremaining: 53.5s\n",
            "1465:\ttotal: 2m 26s\tremaining: 53.4s\n",
            "1466:\ttotal: 2m 26s\tremaining: 53.3s\n",
            "1467:\ttotal: 2m 26s\tremaining: 53.2s\n",
            "1468:\ttotal: 2m 26s\tremaining: 53.1s\n",
            "1469:\ttotal: 2m 26s\tremaining: 53s\n",
            "1470:\ttotal: 2m 27s\tremaining: 52.9s\n",
            "1471:\ttotal: 2m 27s\tremaining: 52.8s\n",
            "1472:\ttotal: 2m 27s\tremaining: 52.7s\n",
            "1473:\ttotal: 2m 27s\tremaining: 52.5s\n",
            "1474:\ttotal: 2m 27s\tremaining: 52.4s\n",
            "1475:\ttotal: 2m 27s\tremaining: 52.3s\n",
            "1476:\ttotal: 2m 27s\tremaining: 52.2s\n",
            "1477:\ttotal: 2m 27s\tremaining: 52.1s\n",
            "1478:\ttotal: 2m 27s\tremaining: 52s\n",
            "1479:\ttotal: 2m 27s\tremaining: 51.9s\n",
            "1480:\ttotal: 2m 27s\tremaining: 51.8s\n",
            "1481:\ttotal: 2m 27s\tremaining: 51.7s\n",
            "1482:\ttotal: 2m 27s\tremaining: 51.6s\n",
            "1483:\ttotal: 2m 27s\tremaining: 51.4s\n",
            "1484:\ttotal: 2m 28s\tremaining: 51.3s\n",
            "1485:\ttotal: 2m 28s\tremaining: 51.3s\n",
            "1486:\ttotal: 2m 28s\tremaining: 51.2s\n",
            "1487:\ttotal: 2m 28s\tremaining: 51.1s\n",
            "1488:\ttotal: 2m 28s\tremaining: 51s\n",
            "1489:\ttotal: 2m 28s\tremaining: 50.8s\n",
            "1490:\ttotal: 2m 28s\tremaining: 50.7s\n",
            "1491:\ttotal: 2m 28s\tremaining: 50.6s\n",
            "1492:\ttotal: 2m 28s\tremaining: 50.5s\n",
            "1493:\ttotal: 2m 28s\tremaining: 50.4s\n",
            "1494:\ttotal: 2m 28s\tremaining: 50.3s\n",
            "1495:\ttotal: 2m 28s\tremaining: 50.2s\n",
            "1496:\ttotal: 2m 28s\tremaining: 50s\n",
            "1497:\ttotal: 2m 29s\tremaining: 49.9s\n",
            "1498:\ttotal: 2m 29s\tremaining: 49.8s\n",
            "1499:\ttotal: 2m 29s\tremaining: 49.7s\n",
            "1500:\ttotal: 2m 29s\tremaining: 49.6s\n",
            "1501:\ttotal: 2m 29s\tremaining: 49.5s\n",
            "1502:\ttotal: 2m 29s\tremaining: 49.4s\n",
            "1503:\ttotal: 2m 29s\tremaining: 49.3s\n",
            "1504:\ttotal: 2m 29s\tremaining: 49.1s\n",
            "1505:\ttotal: 2m 29s\tremaining: 49s\n",
            "1506:\ttotal: 2m 29s\tremaining: 48.9s\n",
            "1507:\ttotal: 2m 29s\tremaining: 48.8s\n",
            "1508:\ttotal: 2m 29s\tremaining: 48.7s\n",
            "1509:\ttotal: 2m 29s\tremaining: 48.6s\n",
            "1510:\ttotal: 2m 29s\tremaining: 48.5s\n",
            "1511:\ttotal: 2m 29s\tremaining: 48.4s\n",
            "1512:\ttotal: 2m 29s\tremaining: 48.3s\n",
            "1513:\ttotal: 2m 29s\tremaining: 48.1s\n",
            "1514:\ttotal: 2m 30s\tremaining: 48s\n",
            "1515:\ttotal: 2m 30s\tremaining: 47.9s\n",
            "1516:\ttotal: 2m 30s\tremaining: 47.8s\n",
            "1517:\ttotal: 2m 30s\tremaining: 47.7s\n",
            "1518:\ttotal: 2m 30s\tremaining: 47.6s\n",
            "1519:\ttotal: 2m 30s\tremaining: 47.5s\n",
            "1520:\ttotal: 2m 30s\tremaining: 47.4s\n",
            "1521:\ttotal: 2m 30s\tremaining: 47.3s\n",
            "1522:\ttotal: 2m 30s\tremaining: 47.1s\n",
            "1523:\ttotal: 2m 30s\tremaining: 47s\n",
            "1524:\ttotal: 2m 30s\tremaining: 46.9s\n",
            "1525:\ttotal: 2m 30s\tremaining: 46.8s\n",
            "1526:\ttotal: 2m 30s\tremaining: 46.7s\n",
            "1527:\ttotal: 2m 30s\tremaining: 46.6s\n",
            "1528:\ttotal: 2m 30s\tremaining: 46.5s\n",
            "1529:\ttotal: 2m 30s\tremaining: 46.4s\n",
            "1530:\ttotal: 2m 31s\tremaining: 46.3s\n",
            "1531:\ttotal: 2m 31s\tremaining: 46.2s\n",
            "1532:\ttotal: 2m 31s\tremaining: 46.1s\n",
            "1533:\ttotal: 2m 31s\tremaining: 45.9s\n",
            "1534:\ttotal: 2m 31s\tremaining: 45.8s\n",
            "1535:\ttotal: 2m 31s\tremaining: 45.7s\n",
            "1536:\ttotal: 2m 31s\tremaining: 45.6s\n",
            "1537:\ttotal: 2m 31s\tremaining: 45.5s\n",
            "1538:\ttotal: 2m 31s\tremaining: 45.4s\n",
            "1539:\ttotal: 2m 31s\tremaining: 45.3s\n",
            "1540:\ttotal: 2m 31s\tremaining: 45.2s\n",
            "1541:\ttotal: 2m 31s\tremaining: 45.1s\n",
            "1542:\ttotal: 2m 31s\tremaining: 45s\n",
            "1543:\ttotal: 2m 31s\tremaining: 44.8s\n",
            "1544:\ttotal: 2m 31s\tremaining: 44.7s\n",
            "1545:\ttotal: 2m 31s\tremaining: 44.6s\n",
            "1546:\ttotal: 2m 32s\tremaining: 44.5s\n",
            "1547:\ttotal: 2m 32s\tremaining: 44.4s\n",
            "1548:\ttotal: 2m 32s\tremaining: 44.3s\n",
            "1549:\ttotal: 2m 32s\tremaining: 44.2s\n",
            "1550:\ttotal: 2m 32s\tremaining: 44.1s\n",
            "1551:\ttotal: 2m 32s\tremaining: 44s\n",
            "1552:\ttotal: 2m 32s\tremaining: 43.9s\n",
            "1553:\ttotal: 2m 32s\tremaining: 43.8s\n",
            "1554:\ttotal: 2m 32s\tremaining: 43.6s\n",
            "1555:\ttotal: 2m 32s\tremaining: 43.5s\n",
            "1556:\ttotal: 2m 32s\tremaining: 43.5s\n",
            "1557:\ttotal: 2m 32s\tremaining: 43.4s\n",
            "1558:\ttotal: 2m 33s\tremaining: 43.3s\n",
            "1559:\ttotal: 2m 33s\tremaining: 43.2s\n",
            "1560:\ttotal: 2m 33s\tremaining: 43.2s\n",
            "1561:\ttotal: 2m 33s\tremaining: 43s\n",
            "1562:\ttotal: 2m 33s\tremaining: 42.9s\n",
            "1563:\ttotal: 2m 33s\tremaining: 42.8s\n",
            "1564:\ttotal: 2m 33s\tremaining: 42.7s\n",
            "1565:\ttotal: 2m 33s\tremaining: 42.6s\n",
            "1566:\ttotal: 2m 33s\tremaining: 42.5s\n",
            "1567:\ttotal: 2m 34s\tremaining: 42.4s\n",
            "1568:\ttotal: 2m 34s\tremaining: 42.3s\n",
            "1569:\ttotal: 2m 34s\tremaining: 42.2s\n",
            "1570:\ttotal: 2m 34s\tremaining: 42.1s\n",
            "1571:\ttotal: 2m 34s\tremaining: 42s\n",
            "1572:\ttotal: 2m 34s\tremaining: 41.9s\n",
            "1573:\ttotal: 2m 34s\tremaining: 41.8s\n",
            "1574:\ttotal: 2m 34s\tremaining: 41.7s\n",
            "1575:\ttotal: 2m 34s\tremaining: 41.6s\n",
            "1576:\ttotal: 2m 34s\tremaining: 41.5s\n",
            "1577:\ttotal: 2m 34s\tremaining: 41.4s\n",
            "1578:\ttotal: 2m 34s\tremaining: 41.3s\n",
            "1579:\ttotal: 2m 35s\tremaining: 41.2s\n",
            "1580:\ttotal: 2m 35s\tremaining: 41.1s\n",
            "1581:\ttotal: 2m 35s\tremaining: 41s\n",
            "1582:\ttotal: 2m 35s\tremaining: 40.9s\n",
            "1583:\ttotal: 2m 35s\tremaining: 40.8s\n",
            "1584:\ttotal: 2m 35s\tremaining: 40.8s\n",
            "1585:\ttotal: 2m 35s\tremaining: 40.7s\n",
            "1586:\ttotal: 2m 35s\tremaining: 40.6s\n",
            "1587:\ttotal: 2m 35s\tremaining: 40.5s\n",
            "1588:\ttotal: 2m 35s\tremaining: 40.3s\n",
            "1589:\ttotal: 2m 36s\tremaining: 40.2s\n",
            "1590:\ttotal: 2m 36s\tremaining: 40.2s\n",
            "1591:\ttotal: 2m 36s\tremaining: 40.1s\n",
            "1592:\ttotal: 2m 36s\tremaining: 40s\n",
            "1593:\ttotal: 2m 36s\tremaining: 39.9s\n",
            "1594:\ttotal: 2m 36s\tremaining: 39.7s\n",
            "1595:\ttotal: 2m 36s\tremaining: 39.6s\n",
            "1596:\ttotal: 2m 36s\tremaining: 39.5s\n",
            "1597:\ttotal: 2m 36s\tremaining: 39.4s\n",
            "1598:\ttotal: 2m 36s\tremaining: 39.3s\n",
            "1599:\ttotal: 2m 36s\tremaining: 39.2s\n",
            "1600:\ttotal: 2m 36s\tremaining: 39.1s\n",
            "1601:\ttotal: 2m 37s\tremaining: 39s\n",
            "1602:\ttotal: 2m 37s\tremaining: 38.9s\n",
            "1603:\ttotal: 2m 37s\tremaining: 38.8s\n",
            "1604:\ttotal: 2m 37s\tremaining: 38.7s\n",
            "1605:\ttotal: 2m 37s\tremaining: 38.6s\n",
            "1606:\ttotal: 2m 37s\tremaining: 38.5s\n",
            "1607:\ttotal: 2m 37s\tremaining: 38.4s\n",
            "1608:\ttotal: 2m 37s\tremaining: 38.3s\n",
            "1609:\ttotal: 2m 37s\tremaining: 38.2s\n",
            "1610:\ttotal: 2m 37s\tremaining: 38.1s\n",
            "1611:\ttotal: 2m 37s\tremaining: 38s\n",
            "1612:\ttotal: 2m 37s\tremaining: 37.9s\n",
            "1613:\ttotal: 2m 38s\tremaining: 37.8s\n",
            "1614:\ttotal: 2m 38s\tremaining: 37.7s\n",
            "1615:\ttotal: 2m 38s\tremaining: 37.6s\n",
            "1616:\ttotal: 2m 38s\tremaining: 37.5s\n",
            "1617:\ttotal: 2m 38s\tremaining: 37.4s\n",
            "1618:\ttotal: 2m 38s\tremaining: 37.3s\n",
            "1619:\ttotal: 2m 38s\tremaining: 37.2s\n",
            "1620:\ttotal: 2m 38s\tremaining: 37.1s\n",
            "1621:\ttotal: 2m 38s\tremaining: 37s\n",
            "1622:\ttotal: 2m 38s\tremaining: 36.9s\n",
            "1623:\ttotal: 2m 38s\tremaining: 36.8s\n",
            "1624:\ttotal: 2m 39s\tremaining: 36.7s\n",
            "1625:\ttotal: 2m 39s\tremaining: 36.6s\n",
            "1626:\ttotal: 2m 39s\tremaining: 36.5s\n",
            "1627:\ttotal: 2m 39s\tremaining: 36.4s\n",
            "1628:\ttotal: 2m 39s\tremaining: 36.3s\n",
            "1629:\ttotal: 2m 39s\tremaining: 36.2s\n",
            "1630:\ttotal: 2m 39s\tremaining: 36.1s\n",
            "1631:\ttotal: 2m 39s\tremaining: 36s\n",
            "1632:\ttotal: 2m 39s\tremaining: 35.9s\n",
            "1633:\ttotal: 2m 39s\tremaining: 35.8s\n",
            "1634:\ttotal: 2m 39s\tremaining: 35.7s\n",
            "1635:\ttotal: 2m 39s\tremaining: 35.6s\n",
            "1636:\ttotal: 2m 39s\tremaining: 35.5s\n",
            "1637:\ttotal: 2m 39s\tremaining: 35.3s\n",
            "1638:\ttotal: 2m 40s\tremaining: 35.2s\n",
            "1639:\ttotal: 2m 40s\tremaining: 35.1s\n",
            "1640:\ttotal: 2m 40s\tremaining: 35s\n",
            "1641:\ttotal: 2m 40s\tremaining: 34.9s\n",
            "1642:\ttotal: 2m 40s\tremaining: 34.8s\n",
            "1643:\ttotal: 2m 40s\tremaining: 34.7s\n",
            "1644:\ttotal: 2m 40s\tremaining: 34.6s\n",
            "1645:\ttotal: 2m 40s\tremaining: 34.5s\n",
            "1646:\ttotal: 2m 40s\tremaining: 34.4s\n",
            "1647:\ttotal: 2m 40s\tremaining: 34.3s\n",
            "1648:\ttotal: 2m 40s\tremaining: 34.2s\n",
            "1649:\ttotal: 2m 40s\tremaining: 34.1s\n",
            "1650:\ttotal: 2m 41s\tremaining: 34.1s\n",
            "1651:\ttotal: 2m 41s\tremaining: 34s\n",
            "1652:\ttotal: 2m 41s\tremaining: 33.9s\n",
            "1653:\ttotal: 2m 41s\tremaining: 33.8s\n",
            "1654:\ttotal: 2m 41s\tremaining: 33.7s\n",
            "1655:\ttotal: 2m 41s\tremaining: 33.6s\n",
            "1656:\ttotal: 2m 41s\tremaining: 33.5s\n",
            "1657:\ttotal: 2m 41s\tremaining: 33.4s\n",
            "1658:\ttotal: 2m 41s\tremaining: 33.3s\n",
            "1659:\ttotal: 2m 41s\tremaining: 33.2s\n",
            "1660:\ttotal: 2m 41s\tremaining: 33s\n",
            "1661:\ttotal: 2m 41s\tremaining: 32.9s\n",
            "1662:\ttotal: 2m 42s\tremaining: 32.8s\n",
            "1663:\ttotal: 2m 42s\tremaining: 32.7s\n",
            "1664:\ttotal: 2m 42s\tremaining: 32.6s\n",
            "1665:\ttotal: 2m 42s\tremaining: 32.5s\n",
            "1666:\ttotal: 2m 42s\tremaining: 32.4s\n",
            "1667:\ttotal: 2m 42s\tremaining: 32.3s\n",
            "1668:\ttotal: 2m 42s\tremaining: 32.2s\n",
            "1669:\ttotal: 2m 42s\tremaining: 32.1s\n",
            "1670:\ttotal: 2m 42s\tremaining: 32s\n",
            "1671:\ttotal: 2m 42s\tremaining: 31.9s\n",
            "1672:\ttotal: 2m 42s\tremaining: 31.8s\n",
            "1673:\ttotal: 2m 42s\tremaining: 31.7s\n",
            "1674:\ttotal: 2m 42s\tremaining: 31.6s\n",
            "1675:\ttotal: 2m 42s\tremaining: 31.5s\n",
            "1676:\ttotal: 2m 42s\tremaining: 31.4s\n",
            "1677:\ttotal: 2m 43s\tremaining: 31.3s\n",
            "1678:\ttotal: 2m 43s\tremaining: 31.2s\n",
            "1679:\ttotal: 2m 43s\tremaining: 31.1s\n",
            "1680:\ttotal: 2m 43s\tremaining: 31s\n",
            "1681:\ttotal: 2m 43s\tremaining: 30.9s\n",
            "1682:\ttotal: 2m 43s\tremaining: 30.8s\n",
            "1683:\ttotal: 2m 43s\tremaining: 30.7s\n",
            "1684:\ttotal: 2m 43s\tremaining: 30.6s\n",
            "1685:\ttotal: 2m 43s\tremaining: 30.5s\n",
            "1686:\ttotal: 2m 43s\tremaining: 30.3s\n",
            "1687:\ttotal: 2m 43s\tremaining: 30.2s\n",
            "1688:\ttotal: 2m 43s\tremaining: 30.1s\n",
            "1689:\ttotal: 2m 43s\tremaining: 30s\n",
            "1690:\ttotal: 2m 43s\tremaining: 29.9s\n",
            "1691:\ttotal: 2m 43s\tremaining: 29.8s\n",
            "1692:\ttotal: 2m 43s\tremaining: 29.7s\n",
            "1693:\ttotal: 2m 44s\tremaining: 29.6s\n",
            "1694:\ttotal: 2m 44s\tremaining: 29.5s\n",
            "1695:\ttotal: 2m 44s\tremaining: 29.4s\n",
            "1696:\ttotal: 2m 44s\tremaining: 29.3s\n",
            "1697:\ttotal: 2m 44s\tremaining: 29.2s\n",
            "1698:\ttotal: 2m 44s\tremaining: 29.1s\n",
            "1699:\ttotal: 2m 44s\tremaining: 29s\n",
            "1700:\ttotal: 2m 44s\tremaining: 28.9s\n",
            "1701:\ttotal: 2m 44s\tremaining: 28.8s\n",
            "1702:\ttotal: 2m 44s\tremaining: 28.7s\n",
            "1703:\ttotal: 2m 44s\tremaining: 28.6s\n",
            "1704:\ttotal: 2m 44s\tremaining: 28.5s\n",
            "1705:\ttotal: 2m 45s\tremaining: 28.4s\n",
            "1706:\ttotal: 2m 45s\tremaining: 28.3s\n",
            "1707:\ttotal: 2m 45s\tremaining: 28.2s\n",
            "1708:\ttotal: 2m 45s\tremaining: 28.1s\n",
            "1709:\ttotal: 2m 45s\tremaining: 28s\n",
            "1710:\ttotal: 2m 45s\tremaining: 27.9s\n",
            "1711:\ttotal: 2m 45s\tremaining: 27.8s\n",
            "1712:\ttotal: 2m 45s\tremaining: 27.7s\n",
            "1713:\ttotal: 2m 45s\tremaining: 27.6s\n",
            "1714:\ttotal: 2m 45s\tremaining: 27.5s\n",
            "1715:\ttotal: 2m 45s\tremaining: 27.4s\n",
            "1716:\ttotal: 2m 45s\tremaining: 27.3s\n",
            "1717:\ttotal: 2m 45s\tremaining: 27.2s\n",
            "1718:\ttotal: 2m 45s\tremaining: 27.1s\n",
            "1719:\ttotal: 2m 45s\tremaining: 27s\n",
            "1720:\ttotal: 2m 46s\tremaining: 26.9s\n",
            "1721:\ttotal: 2m 46s\tremaining: 26.8s\n",
            "1722:\ttotal: 2m 46s\tremaining: 26.7s\n",
            "1723:\ttotal: 2m 46s\tremaining: 26.6s\n",
            "1724:\ttotal: 2m 46s\tremaining: 26.5s\n",
            "1725:\ttotal: 2m 46s\tremaining: 26.4s\n",
            "1726:\ttotal: 2m 46s\tremaining: 26.3s\n",
            "1727:\ttotal: 2m 46s\tremaining: 26.2s\n",
            "1728:\ttotal: 2m 46s\tremaining: 26.1s\n",
            "1729:\ttotal: 2m 46s\tremaining: 26.1s\n",
            "1730:\ttotal: 2m 47s\tremaining: 26s\n",
            "1731:\ttotal: 2m 47s\tremaining: 25.9s\n",
            "1732:\ttotal: 2m 47s\tremaining: 25.8s\n",
            "1733:\ttotal: 2m 47s\tremaining: 25.7s\n",
            "1734:\ttotal: 2m 47s\tremaining: 25.6s\n",
            "1735:\ttotal: 2m 47s\tremaining: 25.5s\n",
            "1736:\ttotal: 2m 47s\tremaining: 25.4s\n",
            "1737:\ttotal: 2m 47s\tremaining: 25.3s\n",
            "1738:\ttotal: 2m 47s\tremaining: 25.2s\n",
            "1739:\ttotal: 2m 47s\tremaining: 25.1s\n",
            "1740:\ttotal: 2m 47s\tremaining: 25s\n",
            "1741:\ttotal: 2m 48s\tremaining: 24.9s\n",
            "1742:\ttotal: 2m 48s\tremaining: 24.8s\n",
            "1743:\ttotal: 2m 48s\tremaining: 24.7s\n",
            "1744:\ttotal: 2m 48s\tremaining: 24.6s\n",
            "1745:\ttotal: 2m 48s\tremaining: 24.5s\n",
            "1746:\ttotal: 2m 48s\tremaining: 24.4s\n",
            "1747:\ttotal: 2m 48s\tremaining: 24.3s\n",
            "1748:\ttotal: 2m 48s\tremaining: 24.2s\n",
            "1749:\ttotal: 2m 48s\tremaining: 24.1s\n",
            "1750:\ttotal: 2m 48s\tremaining: 24s\n",
            "1751:\ttotal: 2m 48s\tremaining: 23.9s\n",
            "1752:\ttotal: 2m 48s\tremaining: 23.8s\n",
            "1753:\ttotal: 2m 48s\tremaining: 23.7s\n",
            "1754:\ttotal: 2m 49s\tremaining: 23.6s\n",
            "1755:\ttotal: 2m 49s\tremaining: 23.5s\n",
            "1756:\ttotal: 2m 49s\tremaining: 23.4s\n",
            "1757:\ttotal: 2m 49s\tremaining: 23.3s\n",
            "1758:\ttotal: 2m 49s\tremaining: 23.2s\n",
            "1759:\ttotal: 2m 49s\tremaining: 23.1s\n",
            "1760:\ttotal: 2m 49s\tremaining: 23s\n",
            "1761:\ttotal: 2m 49s\tremaining: 22.9s\n",
            "1762:\ttotal: 2m 49s\tremaining: 22.8s\n",
            "1763:\ttotal: 2m 49s\tremaining: 22.7s\n",
            "1764:\ttotal: 2m 49s\tremaining: 22.6s\n",
            "1765:\ttotal: 2m 49s\tremaining: 22.5s\n",
            "1766:\ttotal: 2m 49s\tremaining: 22.4s\n",
            "1767:\ttotal: 2m 49s\tremaining: 22.3s\n",
            "1768:\ttotal: 2m 49s\tremaining: 22.2s\n",
            "1769:\ttotal: 2m 49s\tremaining: 22.1s\n",
            "1770:\ttotal: 2m 49s\tremaining: 22s\n",
            "1771:\ttotal: 2m 50s\tremaining: 21.9s\n",
            "1772:\ttotal: 2m 50s\tremaining: 21.8s\n",
            "1773:\ttotal: 2m 50s\tremaining: 21.7s\n",
            "1774:\ttotal: 2m 50s\tremaining: 21.6s\n",
            "1775:\ttotal: 2m 50s\tremaining: 21.5s\n",
            "1776:\ttotal: 2m 50s\tremaining: 21.4s\n",
            "1777:\ttotal: 2m 50s\tremaining: 21.3s\n",
            "1778:\ttotal: 2m 50s\tremaining: 21.2s\n",
            "1779:\ttotal: 2m 50s\tremaining: 21.1s\n",
            "1780:\ttotal: 2m 50s\tremaining: 21s\n",
            "1781:\ttotal: 2m 50s\tremaining: 20.9s\n",
            "1782:\ttotal: 2m 50s\tremaining: 20.8s\n",
            "1783:\ttotal: 2m 50s\tremaining: 20.7s\n",
            "1784:\ttotal: 2m 50s\tremaining: 20.6s\n",
            "1785:\ttotal: 2m 50s\tremaining: 20.5s\n",
            "1786:\ttotal: 2m 50s\tremaining: 20.4s\n",
            "1787:\ttotal: 2m 50s\tremaining: 20.3s\n",
            "1788:\ttotal: 2m 51s\tremaining: 20.2s\n",
            "1789:\ttotal: 2m 51s\tremaining: 20.1s\n",
            "1790:\ttotal: 2m 51s\tremaining: 20s\n",
            "1791:\ttotal: 2m 51s\tremaining: 19.9s\n",
            "1792:\ttotal: 2m 51s\tremaining: 19.8s\n",
            "1793:\ttotal: 2m 51s\tremaining: 19.7s\n",
            "1794:\ttotal: 2m 51s\tremaining: 19.6s\n",
            "1795:\ttotal: 2m 52s\tremaining: 19.6s\n",
            "1796:\ttotal: 2m 52s\tremaining: 19.5s\n",
            "1797:\ttotal: 2m 52s\tremaining: 19.4s\n",
            "1798:\ttotal: 2m 52s\tremaining: 19.3s\n",
            "1799:\ttotal: 2m 52s\tremaining: 19.2s\n",
            "1800:\ttotal: 2m 52s\tremaining: 19.1s\n",
            "1801:\ttotal: 2m 52s\tremaining: 19s\n",
            "1802:\ttotal: 2m 53s\tremaining: 18.9s\n",
            "1803:\ttotal: 2m 53s\tremaining: 18.8s\n",
            "1804:\ttotal: 2m 53s\tremaining: 18.7s\n",
            "1805:\ttotal: 2m 53s\tremaining: 18.6s\n",
            "1806:\ttotal: 2m 53s\tremaining: 18.5s\n",
            "1807:\ttotal: 2m 53s\tremaining: 18.4s\n",
            "1808:\ttotal: 2m 53s\tremaining: 18.3s\n",
            "1809:\ttotal: 2m 53s\tremaining: 18.2s\n",
            "1810:\ttotal: 2m 53s\tremaining: 18.1s\n",
            "1811:\ttotal: 2m 53s\tremaining: 18s\n",
            "1812:\ttotal: 2m 53s\tremaining: 17.9s\n",
            "1813:\ttotal: 2m 53s\tremaining: 17.8s\n",
            "1814:\ttotal: 2m 53s\tremaining: 17.7s\n",
            "1815:\ttotal: 2m 53s\tremaining: 17.6s\n",
            "1816:\ttotal: 2m 53s\tremaining: 17.5s\n",
            "1817:\ttotal: 2m 54s\tremaining: 17.4s\n",
            "1818:\ttotal: 2m 54s\tremaining: 17.3s\n",
            "1819:\ttotal: 2m 54s\tremaining: 17.2s\n",
            "1820:\ttotal: 2m 54s\tremaining: 17.1s\n",
            "1821:\ttotal: 2m 54s\tremaining: 17s\n",
            "1822:\ttotal: 2m 54s\tremaining: 17s\n",
            "1823:\ttotal: 2m 54s\tremaining: 16.9s\n",
            "1824:\ttotal: 2m 54s\tremaining: 16.8s\n",
            "1825:\ttotal: 2m 54s\tremaining: 16.7s\n",
            "1826:\ttotal: 2m 54s\tremaining: 16.6s\n",
            "1827:\ttotal: 2m 54s\tremaining: 16.5s\n",
            "1828:\ttotal: 2m 54s\tremaining: 16.4s\n",
            "1829:\ttotal: 2m 55s\tremaining: 16.3s\n",
            "1830:\ttotal: 2m 55s\tremaining: 16.2s\n",
            "1831:\ttotal: 2m 55s\tremaining: 16.1s\n",
            "1832:\ttotal: 2m 55s\tremaining: 16s\n",
            "1833:\ttotal: 2m 55s\tremaining: 15.9s\n",
            "1834:\ttotal: 2m 55s\tremaining: 15.8s\n",
            "1835:\ttotal: 2m 55s\tremaining: 15.7s\n",
            "1836:\ttotal: 2m 55s\tremaining: 15.6s\n",
            "1837:\ttotal: 2m 55s\tremaining: 15.5s\n",
            "1838:\ttotal: 2m 55s\tremaining: 15.4s\n",
            "1839:\ttotal: 2m 56s\tremaining: 15.3s\n",
            "1840:\ttotal: 2m 56s\tremaining: 15.2s\n",
            "1841:\ttotal: 2m 56s\tremaining: 15.1s\n",
            "1842:\ttotal: 2m 56s\tremaining: 15s\n",
            "1843:\ttotal: 2m 56s\tremaining: 14.9s\n",
            "1844:\ttotal: 2m 56s\tremaining: 14.9s\n",
            "1845:\ttotal: 2m 57s\tremaining: 14.8s\n",
            "1846:\ttotal: 2m 57s\tremaining: 14.7s\n",
            "1847:\ttotal: 2m 57s\tremaining: 14.6s\n",
            "1848:\ttotal: 2m 57s\tremaining: 14.5s\n",
            "1849:\ttotal: 2m 57s\tremaining: 14.4s\n",
            "1850:\ttotal: 2m 57s\tremaining: 14.3s\n",
            "1851:\ttotal: 2m 57s\tremaining: 14.2s\n",
            "1852:\ttotal: 2m 57s\tremaining: 14.1s\n",
            "1853:\ttotal: 2m 57s\tremaining: 14s\n",
            "1854:\ttotal: 2m 57s\tremaining: 13.9s\n",
            "1855:\ttotal: 2m 58s\tremaining: 13.8s\n",
            "1856:\ttotal: 2m 58s\tremaining: 13.7s\n",
            "1857:\ttotal: 2m 58s\tremaining: 13.6s\n",
            "1858:\ttotal: 2m 58s\tremaining: 13.5s\n",
            "1859:\ttotal: 2m 58s\tremaining: 13.4s\n",
            "1860:\ttotal: 2m 58s\tremaining: 13.3s\n",
            "1861:\ttotal: 2m 58s\tremaining: 13.2s\n",
            "1862:\ttotal: 2m 58s\tremaining: 13.1s\n",
            "1863:\ttotal: 2m 58s\tremaining: 13s\n",
            "1864:\ttotal: 2m 58s\tremaining: 12.9s\n",
            "1865:\ttotal: 2m 58s\tremaining: 12.8s\n",
            "1866:\ttotal: 2m 58s\tremaining: 12.7s\n",
            "1867:\ttotal: 2m 58s\tremaining: 12.6s\n",
            "1868:\ttotal: 2m 58s\tremaining: 12.5s\n",
            "1869:\ttotal: 2m 58s\tremaining: 12.4s\n",
            "1870:\ttotal: 2m 59s\tremaining: 12.3s\n",
            "1871:\ttotal: 2m 59s\tremaining: 12.2s\n",
            "1872:\ttotal: 2m 59s\tremaining: 12.2s\n",
            "1873:\ttotal: 2m 59s\tremaining: 12.1s\n",
            "1874:\ttotal: 2m 59s\tremaining: 12s\n",
            "1875:\ttotal: 2m 59s\tremaining: 11.9s\n",
            "1876:\ttotal: 2m 59s\tremaining: 11.8s\n",
            "1877:\ttotal: 2m 59s\tremaining: 11.7s\n",
            "1878:\ttotal: 3m\tremaining: 11.6s\n",
            "1879:\ttotal: 3m\tremaining: 11.5s\n",
            "1880:\ttotal: 3m\tremaining: 11.4s\n",
            "1881:\ttotal: 3m\tremaining: 11.3s\n",
            "1882:\ttotal: 3m\tremaining: 11.2s\n",
            "1883:\ttotal: 3m\tremaining: 11.1s\n",
            "1884:\ttotal: 3m\tremaining: 11s\n",
            "1885:\ttotal: 3m\tremaining: 10.9s\n",
            "1886:\ttotal: 3m\tremaining: 10.8s\n",
            "1887:\ttotal: 3m\tremaining: 10.7s\n",
            "1888:\ttotal: 3m 1s\tremaining: 10.6s\n",
            "1889:\ttotal: 3m 1s\tremaining: 10.5s\n",
            "1890:\ttotal: 3m 1s\tremaining: 10.4s\n",
            "1891:\ttotal: 3m 1s\tremaining: 10.3s\n",
            "1892:\ttotal: 3m 1s\tremaining: 10.3s\n",
            "1893:\ttotal: 3m 1s\tremaining: 10.2s\n",
            "1894:\ttotal: 3m 1s\tremaining: 10.1s\n",
            "1895:\ttotal: 3m 1s\tremaining: 9.96s\n",
            "1896:\ttotal: 3m 1s\tremaining: 9.86s\n",
            "1897:\ttotal: 3m 1s\tremaining: 9.77s\n",
            "1898:\ttotal: 3m 1s\tremaining: 9.67s\n",
            "1899:\ttotal: 3m 1s\tremaining: 9.57s\n",
            "1900:\ttotal: 3m 1s\tremaining: 9.47s\n",
            "1901:\ttotal: 3m 2s\tremaining: 9.38s\n",
            "1902:\ttotal: 3m 2s\tremaining: 9.28s\n",
            "1903:\ttotal: 3m 2s\tremaining: 9.19s\n",
            "1904:\ttotal: 3m 2s\tremaining: 9.09s\n",
            "1905:\ttotal: 3m 2s\tremaining: 8.99s\n",
            "1906:\ttotal: 3m 2s\tremaining: 8.89s\n",
            "1907:\ttotal: 3m 2s\tremaining: 8.8s\n",
            "1908:\ttotal: 3m 2s\tremaining: 8.7s\n",
            "1909:\ttotal: 3m 2s\tremaining: 8.6s\n",
            "1910:\ttotal: 3m 2s\tremaining: 8.51s\n",
            "1911:\ttotal: 3m 2s\tremaining: 8.41s\n",
            "1912:\ttotal: 3m 2s\tremaining: 8.31s\n",
            "1913:\ttotal: 3m 2s\tremaining: 8.22s\n",
            "1914:\ttotal: 3m 2s\tremaining: 8.12s\n",
            "1915:\ttotal: 3m 3s\tremaining: 8.02s\n",
            "1916:\ttotal: 3m 3s\tremaining: 7.93s\n",
            "1917:\ttotal: 3m 3s\tremaining: 7.84s\n",
            "1918:\ttotal: 3m 3s\tremaining: 7.74s\n",
            "1919:\ttotal: 3m 3s\tremaining: 7.65s\n",
            "1920:\ttotal: 3m 3s\tremaining: 7.55s\n",
            "1921:\ttotal: 3m 3s\tremaining: 7.45s\n",
            "1922:\ttotal: 3m 3s\tremaining: 7.36s\n",
            "1923:\ttotal: 3m 3s\tremaining: 7.26s\n",
            "1924:\ttotal: 3m 3s\tremaining: 7.16s\n",
            "1925:\ttotal: 3m 3s\tremaining: 7.07s\n",
            "1926:\ttotal: 3m 3s\tremaining: 6.97s\n",
            "1927:\ttotal: 3m 4s\tremaining: 6.87s\n",
            "1928:\ttotal: 3m 4s\tremaining: 6.78s\n",
            "1929:\ttotal: 3m 4s\tremaining: 6.68s\n",
            "1930:\ttotal: 3m 4s\tremaining: 6.59s\n",
            "1931:\ttotal: 3m 4s\tremaining: 6.49s\n",
            "1932:\ttotal: 3m 4s\tremaining: 6.4s\n",
            "1933:\ttotal: 3m 4s\tremaining: 6.3s\n",
            "1934:\ttotal: 3m 4s\tremaining: 6.2s\n",
            "1935:\ttotal: 3m 4s\tremaining: 6.11s\n",
            "1936:\ttotal: 3m 4s\tremaining: 6.01s\n",
            "1937:\ttotal: 3m 4s\tremaining: 5.92s\n",
            "1938:\ttotal: 3m 5s\tremaining: 5.82s\n",
            "1939:\ttotal: 3m 5s\tremaining: 5.73s\n",
            "1940:\ttotal: 3m 5s\tremaining: 5.63s\n",
            "1941:\ttotal: 3m 5s\tremaining: 5.54s\n",
            "1942:\ttotal: 3m 5s\tremaining: 5.44s\n",
            "1943:\ttotal: 3m 5s\tremaining: 5.35s\n",
            "1944:\ttotal: 3m 5s\tremaining: 5.25s\n",
            "1945:\ttotal: 3m 5s\tremaining: 5.15s\n",
            "1946:\ttotal: 3m 5s\tremaining: 5.06s\n",
            "1947:\ttotal: 3m 5s\tremaining: 4.96s\n",
            "1948:\ttotal: 3m 5s\tremaining: 4.86s\n",
            "1949:\ttotal: 3m 5s\tremaining: 4.77s\n",
            "1950:\ttotal: 3m 6s\tremaining: 4.67s\n",
            "1951:\ttotal: 3m 6s\tremaining: 4.58s\n",
            "1952:\ttotal: 3m 6s\tremaining: 4.48s\n",
            "1953:\ttotal: 3m 6s\tremaining: 4.38s\n",
            "1954:\ttotal: 3m 6s\tremaining: 4.29s\n",
            "1955:\ttotal: 3m 6s\tremaining: 4.19s\n",
            "1956:\ttotal: 3m 6s\tremaining: 4.1s\n",
            "1957:\ttotal: 3m 6s\tremaining: 4s\n",
            "1958:\ttotal: 3m 6s\tremaining: 3.9s\n",
            "1959:\ttotal: 3m 6s\tremaining: 3.81s\n",
            "1960:\ttotal: 3m 6s\tremaining: 3.71s\n",
            "1961:\ttotal: 3m 6s\tremaining: 3.62s\n",
            "1962:\ttotal: 3m 6s\tremaining: 3.52s\n",
            "1963:\ttotal: 3m 7s\tremaining: 3.43s\n",
            "1964:\ttotal: 3m 7s\tremaining: 3.33s\n",
            "1965:\ttotal: 3m 7s\tremaining: 3.24s\n",
            "1966:\ttotal: 3m 7s\tremaining: 3.14s\n",
            "1967:\ttotal: 3m 7s\tremaining: 3.05s\n",
            "1968:\ttotal: 3m 7s\tremaining: 2.95s\n",
            "1969:\ttotal: 3m 7s\tremaining: 2.85s\n",
            "1970:\ttotal: 3m 7s\tremaining: 2.76s\n",
            "1971:\ttotal: 3m 7s\tremaining: 2.66s\n",
            "1972:\ttotal: 3m 7s\tremaining: 2.57s\n",
            "1973:\ttotal: 3m 7s\tremaining: 2.47s\n",
            "1974:\ttotal: 3m 7s\tremaining: 2.38s\n",
            "1975:\ttotal: 3m 8s\tremaining: 2.29s\n",
            "1976:\ttotal: 3m 8s\tremaining: 2.19s\n",
            "1977:\ttotal: 3m 8s\tremaining: 2.09s\n",
            "1978:\ttotal: 3m 8s\tremaining: 2s\n",
            "1979:\ttotal: 3m 8s\tremaining: 1.9s\n",
            "1980:\ttotal: 3m 8s\tremaining: 1.81s\n",
            "1981:\ttotal: 3m 8s\tremaining: 1.71s\n",
            "1982:\ttotal: 3m 8s\tremaining: 1.62s\n",
            "1983:\ttotal: 3m 8s\tremaining: 1.52s\n",
            "1984:\ttotal: 3m 8s\tremaining: 1.43s\n",
            "1985:\ttotal: 3m 8s\tremaining: 1.33s\n",
            "1986:\ttotal: 3m 8s\tremaining: 1.24s\n",
            "1987:\ttotal: 3m 8s\tremaining: 1.14s\n",
            "1988:\ttotal: 3m 9s\tremaining: 1.04s\n",
            "1989:\ttotal: 3m 9s\tremaining: 950ms\n",
            "1990:\ttotal: 3m 9s\tremaining: 855ms\n",
            "1991:\ttotal: 3m 9s\tremaining: 760ms\n",
            "1992:\ttotal: 3m 9s\tremaining: 665ms\n",
            "1993:\ttotal: 3m 9s\tremaining: 570ms\n",
            "1994:\ttotal: 3m 9s\tremaining: 475ms\n",
            "1995:\ttotal: 3m 9s\tremaining: 380ms\n",
            "1996:\ttotal: 3m 9s\tremaining: 285ms\n",
            "1997:\ttotal: 3m 9s\tremaining: 190ms\n",
            "1998:\ttotal: 3m 9s\tremaining: 94.9ms\n",
            "1999:\ttotal: 3m 9s\tremaining: 0us\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x224a1ab2190>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "catboost = CatBoostClassifier(iterations = 2000, eval_metric = \"AUC\")\n",
        "catboost.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "g1FvcDLr7wTb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[21514  1203]\n",
            " [ 2796  3579]]\n",
            "\n",
            "Accuracy = 86.25%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.88      0.95      0.91     22717\n",
            "        True       0.75      0.56      0.64      6375\n",
            "\n",
            "    accuracy                           0.86     29092\n",
            "   macro avg       0.82      0.75      0.78     29092\n",
            "weighted avg       0.86      0.86      0.86     29092\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred_proba = catboost.predict_proba(X_test)\n",
        "\n",
        "y_pred_proba_pos = y_pred_proba[:, 1]\n",
        "\n",
        "threshold = 0.5\n",
        "\n",
        "y_pred88 = (y_pred_proba_pos >= threshold).astype(int)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred88))\n",
        "\n",
        "accuracy88 = accuracy_score(y_test, y_pred88)\n",
        "print(f'\\nAccuracy = {accuracy88 * 100 :.2f}%')\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred88))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ7d5epT7wTl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
